{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-07-02T14:28:19.282233Z",
     "iopub.status.busy": "2025-07-02T14:28:19.281478Z",
     "iopub.status.idle": "2025-07-02T14:28:19.304354Z",
     "shell.execute_reply": "2025-07-02T14:28:19.303636Z",
     "shell.execute_reply.started": "2025-07-02T14:28:19.282204Z"
    },
    "id": "UItyQbFQLUwo",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)4\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, mean_absolute_percentage_error, explained_variance_score\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Input, Dense, Bidirectional, LSTM, Lambda, Concatenate, Add, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "def set_random_seed(seed=20):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    tf.config.experimental.enable_op_determinism()\n",
    "\n",
    "set_random_seed(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ySzAOB-oLUwr"
   },
   "source": [
    "# OUR RANGE: SENSEX (15-3-2008 to 15-3-2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "execution": {
     "iopub.execute_input": "2025-07-02T14:28:19.306445Z",
     "iopub.status.busy": "2025-07-02T14:28:19.306268Z",
     "iopub.status.idle": "2025-07-02T14:28:19.371623Z",
     "shell.execute_reply": "2025-07-02T14:28:19.371073Z",
     "shell.execute_reply.started": "2025-07-02T14:28:19.306431Z"
    },
    "id": "nXbVv0LsLUws",
    "outputId": "50a1e8fc-b716-4d4a-ec81-5f236884c7d1",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "vix = pd.read_csv(\"/kaggle/input/our-data-15-3-2008-to-15-3-2024/India VIX Historical Data (3).csv\")\n",
    "vix.drop(\"Vol.\",axis=1,inplace=True)\n",
    "vix[\"Change %\"] = vix[\"Change %\"].str.replace(\"%\", \"\").astype(float)\n",
    "vix.head(),vix.dtypes\n",
    "data=pd.read_csv(\"/kaggle/input/our-data-15-3-2008-to-15-3-2024/BSE Sensex 30 Historical Data (3).csv\")\n",
    "data=data[::-1]\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "data.head()\n",
    "data.nunique()\n",
    "\n",
    "data.sort_index(axis=1,ascending=True)\n",
    "data.rename(columns={'Price': 'Close'}, inplace=True)\n",
    "df = data.copy()  # Ensure we don't modify the original dataset\n",
    "\n",
    "# Convert financial columns to numeric (remove commas)\n",
    "for col in [\"Close\", \"Open\", \"High\", \"Low\"]:\n",
    "    df[col] = df[col].astype(str).str.replace(\",\", \"\").astype(float)\n",
    "\n",
    "# Function to convert 'Vol.' column\n",
    "def convert_volume(vol):\n",
    "    if isinstance(vol, str):  # Ensure it's a string before replacing\n",
    "        vol = vol.replace(\",\", \"\")  # Remove any thousand separators\n",
    "        if \"B\" in vol:\n",
    "            return float(vol.replace(\"B\", \"\")) * 1_000_000_000\n",
    "        elif \"M\" in vol:\n",
    "            return float(vol.replace(\"M\", \"\")) * 1_000_000\n",
    "        elif \"K\" in vol:\n",
    "            return float(vol.replace(\"K\", \"\")) * 1_000\n",
    "    return float(vol)  # Convert directly if already a number\n",
    "\n",
    "df[\"Vol.\"] = df[\"Vol.\"].astype(str).apply(convert_volume)\n",
    "\n",
    "# Convert 'Change %' column (remove '%' and convert to float)\n",
    "df[\"Change %\"] = df[\"Change %\"].astype(str).str.replace(\"%\", \"\").astype(float)\n",
    "\n",
    "# Print final DataFrame\n",
    "print(df.dtypes)\n",
    "print(df)\n",
    "\n",
    "# Assign back to 'data' (if needed)\n",
    "data = df\n",
    "\n",
    "data = pd.merge(data, vix, on='Date', how='inner')\n",
    "data.drop(['Date'], axis=1, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T14:28:19.372461Z",
     "iopub.status.busy": "2025-07-02T14:28:19.372267Z",
     "iopub.status.idle": "2025-07-02T14:28:19.397283Z",
     "shell.execute_reply": "2025-07-02T14:28:19.396717Z",
     "shell.execute_reply.started": "2025-07-02T14:28:19.372437Z"
    },
    "id": "jhs3PehLLUws",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, mean_absolute_percentage_error, explained_variance_score\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Input, Dense, Bidirectional, LSTM, Lambda, Concatenate, Add, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# 2. Load & Preprocess Data\n",
    "# ---------------------------\n",
    "# For demonstration, we use a basic univariate \"Close\" series.\n",
    "# Ensure that your DataFrame 'data' contains at least a \"Close\" column.\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# ---------------------------\n",
    "# 2. Load & Preprocess Data\n",
    "# ---------------------------\n",
    "# Separate features (X) and target (y)\n",
    "y = data[['Close']].copy()\n",
    "X = data.drop('Close', axis=1).copy()\n",
    "\n",
    "# It's important to scale your features and target separately.\n",
    "# We'll need the 'scaler_y' later to inverse the transformation of our predictions.\n",
    "scaler_X = MinMaxScaler()\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "\n",
    "scaler_y = MinMaxScaler()\n",
    "y_scaled = scaler_y.fit_transform(y)\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# 3. Create 15-day Sequences for Multivariate Data\n",
    "# ---------------------------\n",
    "def create_multivariate_sequences(X_data, y_data, time_steps=15):\n",
    "    \"\"\"\n",
    "    Creates sequences for multivariate time series data.\n",
    "    \"\"\"\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X_data) - time_steps):\n",
    "        # Get a sequence of 'time_steps' from the features\n",
    "        Xs.append(X_data[i:(i + time_steps)])\n",
    "        # The target is the 'Close' price at the end of the sequence\n",
    "        ys.append(y_data[i + time_steps])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "\n",
    "# Create the sequences\n",
    "X_seq, y_seq = create_multivariate_sequences(X_scaled, y_scaled, time_steps=15)\n",
    "\n",
    "# Split the data into training, validation, and testing sets\n",
    "train_size = int(len(X_seq) * 0.7)\n",
    "val_size = int(len(X_seq) * 0.1)\n",
    "\n",
    "X_train, y_train = X_seq[:train_size], y_seq[:train_size]\n",
    "X_val, y_val = X_seq[train_size:train_size + val_size], y_seq[train_size:train_size + val_size]\n",
    "X_test, y_test = X_seq[train_size + val_size:], y_seq[train_size + val_size:]\n",
    "\n",
    "# The input for the model will have a shape of (number of samples, timesteps, number of features)\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "n_features = X.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HVWV3WL9LUwt"
   },
   "source": [
    "## with single LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T14:28:19.464654Z",
     "iopub.status.busy": "2025-07-02T14:28:19.464450Z",
     "iopub.status.idle": "2025-07-02T14:29:21.893868Z",
     "shell.execute_reply": "2025-07-02T14:29:21.893077Z",
     "shell.execute_reply.started": "2025-07-02T14:28:19.464637Z"
    },
    "id": "Xr8S8kGSLUwt",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.layers import Multiply, Activation\n",
    "\n",
    "def build_lstm_model(seq_length=15,n_features=n_features, scale_factor=0.2, recent_scale=0.1):\n",
    "    inputs = Input(shape=(seq_length, n_features))\n",
    "    # Simple LSTM (unidirectional)\n",
    "    x = LSTM(128, return_sequences=False, dropout=0.2)(inputs)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dense(1, activation='tanh')(x)\n",
    "    x = Lambda(lambda x: x * scale_factor)(x)\n",
    "\n",
    "    # Use the last day's price for final output calculation\n",
    "    last_day = Lambda(lambda x: tf.expand_dims(x[:, -1, 0], axis=-1))(inputs)\n",
    "    final_output = Lambda(lambda inputs: inputs[0] * (1 + inputs[1]))([last_day, x])\n",
    "\n",
    "    model = Model(inputs, final_output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "    return model\n",
    "\n",
    "# *Build the Modified Model with Gating*\n",
    "# model_gated = build_gated_multi_scale_model(seq_length=15, scale_factor=0.2, recent_scale=0.1)\n",
    "# model_gated.summary()\n",
    "\n",
    "# *Build the Modified Model with Attention-Based Residuals*\n",
    "model_attention = build_lstm_model(seq_length=15, scale_factor=0.2, recent_scale=0.1)\n",
    "model_attention.summary()\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", patience=15, restore_best_weights=True, verbose=1)\n",
    "history = model_attention.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val), batch_size=8, callbacks=[early_stop], verbose=1)\n",
    "\n",
    "# ---------------------------\n",
    "# 7. Evaluate the Model\n",
    "# ---------------------------\n",
    "y_pred = model_attention.predict(X_test)\n",
    "# Predictions on test set\n",
    "##y_pred = model.predict(X_test)\n",
    "\n",
    "# Inverse transform predictions and actual values\n",
    "y_pred_inv = scaler_y.inverse_transform(y_pred)\n",
    "y_test_inv = scaler_y.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Inverse transform predictions and actual values\n",
    "y_pred_inv = scaler_y.inverse_transform(y_pred)\n",
    "y_test_inv = scaler_y.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Calculate Metrics\n",
    "r2 = r2_score(y_test_inv, y_pred_inv)\n",
    "mae = mean_absolute_error(y_test_inv, y_pred_inv)\n",
    "mse = mean_squared_error(y_test_inv, y_pred_inv)\n",
    "rmse = np.sqrt(mse)  # Root Mean Squared Error\n",
    "\n",
    "# Calculate the actual range of the test set\n",
    "actual_range = np.max(y_test_inv) - np.min(y_test_inv)\n",
    "\n",
    "# Compute Scaled Metrics\n",
    "mae_scaled = mae / actual_range\n",
    "mse_scaled = mse / (actual_range ** 2)\n",
    "rmse_scaled = rmse / actual_range\n",
    "\n",
    "# Explained Variance Score\n",
    "evs = explained_variance_score(y_test_inv, y_pred_inv)\n",
    "\n",
    "# Print the results\n",
    "print(f\"ðŸ“Š Final Results -\")\n",
    "print(f\"  RÂ²: {r2:.4f}\")\n",
    "print(f\"  MAE: {mae:.4f}, MAE Scaled: {mae_scaled:.4f}\")\n",
    "print(f\"  MSE: {mse:.4f}, MSE Scaled: {mse_scaled:.4f}\")\n",
    "print(f\"  RMSE: {rmse:.4f}, RMSE Scaled: {rmse_scaled:.4f}\")\n",
    "print(f\"  MAPE: {mean_absolute_percentage_error(y_test_inv, y_pred_inv) * 100:.2f}%\")\n",
    "print(f\"  EVS: {evs:.4f}\")\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot the first 100 points for better visibility\n",
    "num_points = min(100, len(y_test_inv))\n",
    "\n",
    "plt.plot(y_test_inv[:num_points], label=\"Actual\", linestyle=\"-\", linewidth=2, marker=\"o\", markersize=3, alpha=0.8)\n",
    "plt.plot(y_pred_inv[:num_points], label=\"Predicted\", linestyle=\"--\", linewidth=2, marker=\"x\", markersize=3, alpha=0.8)\n",
    "\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Stock Price\")\n",
    "plt.title(\"Actual vs Predicted Stock Prices (Zoomed In)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7sSZYJ6uLUwt"
   },
   "source": [
    "## 15â€‘Day Branch with Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T14:29:21.895706Z",
     "iopub.status.busy": "2025-07-02T14:29:21.895432Z",
     "iopub.status.idle": "2025-07-02T14:30:54.717865Z",
     "shell.execute_reply": "2025-07-02T14:30:54.717107Z",
     "shell.execute_reply.started": "2025-07-02T14:29:21.895682Z"
    },
    "id": "tu3xw6sALUwu",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.layers import Multiply, Activation\n",
    "\n",
    "def build_Bilstm1_model(seq_length=15,n_features=n_features, scale_factor=0.2, recent_scale=0.1):\n",
    "    inputs = Input(shape=(seq_length, n_features))\n",
    "    # 15-day full branch with BiLSTM\n",
    "    x = Bidirectional(LSTM(128, return_sequences=False, dropout=0.2))(inputs)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dense(1, activation='tanh')(x)\n",
    "    x = Lambda(lambda x: x * scale_factor)(x)\n",
    "\n",
    "    last_day = Lambda(lambda x: tf.expand_dims(x[:, -1, 0], axis=-1))(inputs)\n",
    "    final_output = Lambda(lambda inputs: inputs[0] * (1 + inputs[1]))([last_day, x])\n",
    "\n",
    "    model = Model(inputs, final_output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "    return model\n",
    "\n",
    "# *Build the Modified Model with Gating*\n",
    "# model_gated = build_gated_multi_scale_model(seq_length=15, scale_factor=0.2, recent_scale=0.1)\n",
    "# model_gated.summary()\n",
    "\n",
    "# *Build the Modified Model with Attention-Based Residuals*\n",
    "model_attention = build_Bilstm1_model(seq_length=15, scale_factor=0.2, recent_scale=0.1)\n",
    "model_attention.summary()\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", patience=15, restore_best_weights=True, verbose=1)\n",
    "history = model_attention.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val), batch_size=8, callbacks=[early_stop], verbose=1)\n",
    "\n",
    "# ---------------------------\n",
    "# 7. Evaluate the Model\n",
    "# ---------------------------\n",
    "y_pred = model_attention.predict(X_test)\n",
    "# Predictions on test set\n",
    "##y_pred = model.predict(X_test)\n",
    "\n",
    "# Inverse transform predictions and actual values\n",
    "y_pred_inv = scaler_y.inverse_transform(y_pred)\n",
    "y_test_inv = scaler_y.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Inverse transform predictions and actual values\n",
    "y_pred_inv = scaler_y.inverse_transform(y_pred)\n",
    "y_test_inv = scaler_y.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Calculate Metrics\n",
    "r2 = r2_score(y_test_inv, y_pred_inv)\n",
    "mae = mean_absolute_error(y_test_inv, y_pred_inv)\n",
    "mse = mean_squared_error(y_test_inv, y_pred_inv)\n",
    "rmse = np.sqrt(mse)  # Root Mean Squared Error\n",
    "\n",
    "# Calculate the actual range of the test set\n",
    "actual_range = np.max(y_test_inv) - np.min(y_test_inv)\n",
    "\n",
    "# Compute Scaled Metrics\n",
    "mae_scaled = mae / actual_range\n",
    "mse_scaled = mse / (actual_range ** 2)\n",
    "rmse_scaled = rmse / actual_range\n",
    "\n",
    "# Explained Variance Score\n",
    "evs = explained_variance_score(y_test_inv, y_pred_inv)\n",
    "\n",
    "# Print the results\n",
    "print(f\"ðŸ“Š Final Results -\")\n",
    "print(f\"  RÂ²: {r2:.4f}\")\n",
    "print(f\"  MAE: {mae:.4f}, MAE Scaled: {mae_scaled:.4f}\")\n",
    "print(f\"  MSE: {mse:.4f}, MSE Scaled: {mse_scaled:.4f}\")\n",
    "print(f\"  RMSE: {rmse:.4f}, RMSE Scaled: {rmse_scaled:.4f}\")\n",
    "print(f\"  MAPE: {mean_absolute_percentage_error(y_test_inv, y_pred_inv) * 100:.2f}%\")\n",
    "print(f\"  EVS: {evs:.4f}\")\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot the first 100 points for better visibility\n",
    "num_points = min(100, len(y_test_inv))\n",
    "\n",
    "plt.plot(y_test_inv[:num_points], label=\"Actual\", linestyle=\"-\", linewidth=2, marker=\"o\", markersize=3, alpha=0.8)\n",
    "plt.plot(y_pred_inv[:num_points], label=\"Predicted\", linestyle=\"--\", linewidth=2, marker=\"x\", markersize=3, alpha=0.8)\n",
    "\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Stock Price\")\n",
    "plt.title(\"Actual vs Predicted Stock Prices (Zoomed In)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N7SaMTQjLUwu"
   },
   "source": [
    "## 15â€‘Day + 7â€‘Day Branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T14:30:54.719022Z",
     "iopub.status.busy": "2025-07-02T14:30:54.718735Z",
     "iopub.status.idle": "2025-07-02T14:35:34.136801Z",
     "shell.execute_reply": "2025-07-02T14:35:34.136036Z",
     "shell.execute_reply.started": "2025-07-02T14:30:54.718998Z"
    },
    "id": "bdbTf3TZLUwv",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.layers import Multiply, Activation\n",
    "\n",
    "def build_Bilstm2_model(seq_length=15,n_features=n_features, scale_factor=0.2, recent_scale=0.1):\n",
    "    inputs = Input(shape=(seq_length, n_features))\n",
    "\n",
    "    # Full branch (15 days)\n",
    "    full_branch = Bidirectional(LSTM(128, return_sequences=False, dropout=0.2))(inputs)\n",
    "    full_branch = Dense(64, activation='relu')(full_branch)\n",
    "    long_term_return = Dense(1, activation='tanh')(full_branch)\n",
    "    long_term_return = Lambda(lambda x: x * scale_factor)(long_term_return)\n",
    "\n",
    "    # Recent branch (last 7 days)\n",
    "    recent_input = Lambda(lambda x: x[:, -7:, :])(inputs)\n",
    "    recent_branch = Bidirectional(LSTM(128, return_sequences=False, dropout=0.2))(recent_input)\n",
    "    recent_branch = Dense(64, activation='relu')(recent_branch)\n",
    "    mid_term_return = Dense(1, activation='tanh')(recent_branch)\n",
    "    mid_term_return = Lambda(lambda x: x * scale_factor)(mid_term_return)\n",
    "\n",
    "    # Gate the 7-day branch output\n",
    "    gate_7 = Dense(1, activation='sigmoid')(mid_term_return)\n",
    "    gated_mid_term_return = Multiply()([mid_term_return, gate_7])\n",
    "\n",
    "    # Fuse the two branches\n",
    "    fused_returns = Add()([long_term_return, gated_mid_term_return])\n",
    "    fused_returns = Dense(32, activation='relu')(fused_returns)\n",
    "    final_return = Dense(1, activation='tanh')(fused_returns)\n",
    "    final_return = Lambda(lambda x: x * scale_factor)(final_return)\n",
    "\n",
    "    last_day = Lambda(lambda x: tf.expand_dims(x[:, -1, 0], axis=-1))(inputs)\n",
    "    final_output = Lambda(lambda inputs: inputs[0] * (1 + inputs[1]))([last_day, final_return])\n",
    "\n",
    "    model = Model(inputs, final_output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "    return model\n",
    "\n",
    "# *Build the Modified Model with Gating*\n",
    "# model_gated = build_gated_multi_scale_model(seq_length=15, scale_factor=0.2, recent_scale=0.1)\n",
    "# model_gated.summary()\n",
    "\n",
    "# *Build the Modified Model with Attention-Based Residuals*\n",
    "model_attention = build_Bilstm2_model(seq_length=15, scale_factor=0.2, recent_scale=0.1)\n",
    "model_attention.summary()\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", patience=15, restore_best_weights=True, verbose=1)\n",
    "history = model_attention.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val), batch_size=8, callbacks=[early_stop], verbose=1)\n",
    "\n",
    "# ---------------------------\n",
    "# 7. Evaluate the Model\n",
    "# ---------------------------\n",
    "y_pred = model_attention.predict(X_test)\n",
    "# Predictions on test set\n",
    "##y_pred = model.predict(X_test)\n",
    "\n",
    "# Inverse transform predictions and actual values\n",
    "y_pred_inv = scaler_y.inverse_transform(y_pred)\n",
    "y_test_inv = scaler_y.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Inverse transform predictions and actual values\n",
    "y_pred_inv = scaler_y.inverse_transform(y_pred)\n",
    "y_test_inv = scaler_y.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Calculate Metrics\n",
    "r2 = r2_score(y_test_inv, y_pred_inv)\n",
    "mae = mean_absolute_error(y_test_inv, y_pred_inv)\n",
    "mse = mean_squared_error(y_test_inv, y_pred_inv)\n",
    "rmse = np.sqrt(mse)  # Root Mean Squared Error\n",
    "\n",
    "# Calculate the actual range of the test set\n",
    "actual_range = np.max(y_test_inv) - np.min(y_test_inv)\n",
    "\n",
    "# Compute Scaled Metrics\n",
    "mae_scaled = mae / actual_range\n",
    "mse_scaled = mse / (actual_range ** 2)\n",
    "rmse_scaled = rmse / actual_range\n",
    "\n",
    "# Explained Variance Score\n",
    "evs = explained_variance_score(y_test_inv, y_pred_inv)\n",
    "\n",
    "# Print the results\n",
    "print(f\"ðŸ“Š Final Results -\")\n",
    "print(f\"  RÂ²: {r2:.4f}\")\n",
    "print(f\"  MAE: {mae:.4f}, MAE Scaled: {mae_scaled:.4f}\")\n",
    "print(f\"  MSE: {mse:.4f}, MSE Scaled: {mse_scaled:.4f}\")\n",
    "print(f\"  RMSE: {rmse:.4f}, RMSE Scaled: {rmse_scaled:.4f}\")\n",
    "print(f\"  MAPE: {mean_absolute_percentage_error(y_test_inv, y_pred_inv) * 100:.2f}%\")\n",
    "print(f\"  EVS: {evs:.4f}\")\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot the first 100 points for better visibility\n",
    "num_points = min(100, len(y_test_inv))\n",
    "\n",
    "plt.plot(y_test_inv[:num_points], label=\"Actual\", linestyle=\"-\", linewidth=2, marker=\"o\", markersize=3, alpha=0.8)\n",
    "plt.plot(y_pred_inv[:num_points], label=\"Predicted\", linestyle=\"--\", linewidth=2, marker=\"x\", markersize=3, alpha=0.8)\n",
    "\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Stock Price\")\n",
    "plt.title(\"Actual vs Predicted Stock Prices (Zoomed In)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9e3uWgXpLUwv"
   },
   "source": [
    "## 7â€‘Day + 1â€‘Day Branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T14:35:34.137762Z",
     "iopub.status.busy": "2025-07-02T14:35:34.137558Z",
     "iopub.status.idle": "2025-07-02T14:37:22.606515Z",
     "shell.execute_reply": "2025-07-02T14:37:22.605726Z",
     "shell.execute_reply.started": "2025-07-02T14:35:34.137745Z"
    },
    "id": "CxY04vj6LUwv",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.layers import Multiply, Activation\n",
    "\n",
    "def build_Bilstm3_model(seq_length=15,n_features=n_features, scale_factor=0.2, recent_scale=0.1):\n",
    "    inputs = Input(shape=(seq_length, n_features))\n",
    "\n",
    "    # Recent branch (last 7 days)\n",
    "    recent_input = Lambda(lambda x: x[:, -7:, :])(inputs)\n",
    "    recent_branch = Bidirectional(LSTM(128, return_sequences=False, dropout=0.2))(recent_input)\n",
    "    recent_branch = Dense(64, activation='relu')(recent_branch)\n",
    "    mid_term_return = Dense(1, activation='tanh')(recent_branch)\n",
    "    mid_term_return = Lambda(lambda x: x * scale_factor)(mid_term_return)\n",
    "\n",
    "    # Very recent branch (last 1 day)\n",
    "    very_recent_input = Lambda(lambda x: x[:, -1:, :])(inputs)\n",
    "    very_recent_branch = Flatten()(very_recent_input)\n",
    "    very_recent_branch = Dense(32, activation='relu')(very_recent_branch)\n",
    "    short_term_return = Dense(1, activation='tanh')(very_recent_branch)\n",
    "    short_term_return = Lambda(lambda x: x * recent_scale)(short_term_return)\n",
    "\n",
    "    # Gating mechanisms\n",
    "    gate_7 = Dense(1, activation='sigmoid')(mid_term_return)\n",
    "    gate_1 = Dense(1, activation='sigmoid')(short_term_return)\n",
    "    gated_mid_term_return = Multiply()([mid_term_return, gate_7])\n",
    "    gated_short_term_return = Multiply()([short_term_return, gate_1])\n",
    "\n",
    "    # Combine gated outputs\n",
    "    fused_returns = Add()([gated_mid_term_return, gated_short_term_return])\n",
    "    fused_returns = Dense(32, activation='relu')(fused_returns)\n",
    "    final_return = Dense(1, activation='tanh')(fused_returns)\n",
    "    final_return = Lambda(lambda x: x * scale_factor)(final_return)\n",
    "\n",
    "    last_day = Lambda(lambda x: tf.expand_dims(x[:, -1, 0], axis=-1))(inputs)\n",
    "    final_output = Lambda(lambda inputs: inputs[0] * (1 + inputs[1]))([last_day, final_return])\n",
    "\n",
    "    model = Model(inputs, final_output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "    return model\n",
    "\n",
    "# *Build the Modified Model with Gating*\n",
    "# model_gated = build_gated_multi_scale_model(seq_length=15, scale_factor=0.2, recent_scale=0.1)\n",
    "# model_gated.summary()\n",
    "\n",
    "# *Build the Modified Model with Attention-Based Residuals*\n",
    "model_attention = build_Bilstm3_model(seq_length=15, scale_factor=0.2, recent_scale=0.1)\n",
    "model_attention.summary()\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", patience=15, restore_best_weights=True, verbose=1)\n",
    "history = model_attention.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val), batch_size=8, callbacks=[early_stop], verbose=1)\n",
    "\n",
    "# ---------------------------\n",
    "# 7. Evaluate the Model\n",
    "# ---------------------------\n",
    "y_pred = model_attention.predict(X_test)\n",
    "# Predictions on test set\n",
    "##y_pred = model.predict(X_test)\n",
    "\n",
    "# Inverse transform predictions and actual values\n",
    "y_pred_inv = scaler_y.inverse_transform(y_pred)\n",
    "y_test_inv = scaler_y.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Inverse transform predictions and actual values\n",
    "y_pred_inv = scaler_y.inverse_transform(y_pred)\n",
    "y_test_inv = scaler_y.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Calculate Metrics\n",
    "r2 = r2_score(y_test_inv, y_pred_inv)\n",
    "mae = mean_absolute_error(y_test_inv, y_pred_inv)\n",
    "mse = mean_squared_error(y_test_inv, y_pred_inv)\n",
    "rmse = np.sqrt(mse)  # Root Mean Squared Error\n",
    "\n",
    "# Calculate the actual range of the test set\n",
    "actual_range = np.max(y_test_inv) - np.min(y_test_inv)\n",
    "\n",
    "# Compute Scaled Metrics\n",
    "mae_scaled = mae / actual_range\n",
    "mse_scaled = mse / (actual_range ** 2)\n",
    "rmse_scaled = rmse / actual_range\n",
    "\n",
    "# Explained Variance Score\n",
    "evs = explained_variance_score(y_test_inv, y_pred_inv)\n",
    "\n",
    "# Print the results\n",
    "print(f\"ðŸ“Š Final Results -\")\n",
    "print(f\"  RÂ²: {r2:.4f}\")\n",
    "print(f\"  MAE: {mae:.4f}, MAE Scaled: {mae_scaled:.4f}\")\n",
    "print(f\"  MSE: {mse:.4f}, MSE Scaled: {mse_scaled:.4f}\")\n",
    "print(f\"  RMSE: {rmse:.4f}, RMSE Scaled: {rmse_scaled:.4f}\")\n",
    "print(f\"  MAPE: {mean_absolute_percentage_error(y_test_inv, y_pred_inv) * 100:.2f}%\")\n",
    "print(f\"  EVS: {evs:.4f}\")\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot the first 100 points for better visibility\n",
    "num_points = min(100, len(y_test_inv))\n",
    "\n",
    "plt.plot(y_test_inv[:num_points], label=\"Actual\", linestyle=\"-\", linewidth=2, marker=\"o\", markersize=3, alpha=0.8)\n",
    "plt.plot(y_pred_inv[:num_points], label=\"Predicted\", linestyle=\"--\", linewidth=2, marker=\"x\", markersize=3, alpha=0.8)\n",
    "\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Stock Price\")\n",
    "plt.title(\"Actual vs Predicted Stock Prices (Zoomed In)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m3AY1yyLLUww"
   },
   "source": [
    "## 15â€‘Day + 1â€‘Day Branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T14:37:22.608494Z",
     "iopub.status.busy": "2025-07-02T14:37:22.608299Z",
     "iopub.status.idle": "2025-07-02T14:39:15.540279Z",
     "shell.execute_reply": "2025-07-02T14:39:15.539535Z",
     "shell.execute_reply.started": "2025-07-02T14:37:22.608479Z"
    },
    "id": "TOn2xZvaLUww",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.layers import Multiply, Activation\n",
    "\n",
    "def build_Bilstm4_model(seq_length=15,n_features=n_features, scale_factor=0.2, recent_scale=0.1):\n",
    "    inputs = Input(shape=(seq_length, n_features))\n",
    "\n",
    "    # Full branch (15 days)\n",
    "    full_branch = Bidirectional(LSTM(128, return_sequences=False, dropout=0.2))(inputs)\n",
    "    full_branch = Dense(64, activation='relu')(full_branch)\n",
    "    long_term_return = Dense(1, activation='tanh')(full_branch)\n",
    "    long_term_return = Lambda(lambda x: x * scale_factor)(long_term_return)\n",
    "\n",
    "    # Very recent branch (last 1 day)\n",
    "    very_recent_input = Lambda(lambda x: x[:, -1:, :])(inputs)\n",
    "    very_recent_branch = Flatten()(very_recent_input)\n",
    "    very_recent_branch = Dense(32, activation='relu')(very_recent_branch)\n",
    "    short_term_return = Dense(1, activation='tanh')(very_recent_branch)\n",
    "    short_term_return = Lambda(lambda x: x * recent_scale)(short_term_return)\n",
    "\n",
    "    # Gate the 1-day branch output\n",
    "    gate_1 = Dense(1, activation='sigmoid')(short_term_return)\n",
    "    gated_short_term_return = Multiply()([short_term_return, gate_1])\n",
    "\n",
    "    # Fuse branches\n",
    "    fused_returns = Add()([long_term_return, gated_short_term_return])\n",
    "    fused_returns = Dense(32, activation='relu')(fused_returns)\n",
    "    final_return = Dense(1, activation='tanh')(fused_returns)\n",
    "    final_return = Lambda(lambda x: x * scale_factor)(final_return)\n",
    "\n",
    "    last_day = Lambda(lambda x: tf.expand_dims(x[:, -1, 0], axis=-1))(inputs)\n",
    "    final_output = Lambda(lambda inputs: inputs[0] * (1 + inputs[1]))([last_day, final_return])\n",
    "\n",
    "    model = Model(inputs, final_output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "    return model\n",
    "\n",
    "# *Build the Modified Model with Gating*\n",
    "# model_gated = build_gated_multi_scale_model(seq_length=15, scale_factor=0.2, recent_scale=0.1)\n",
    "# model_gated.summary()\n",
    "\n",
    "# *Build the Modified Model with Attention-Based Residuals*\n",
    "model_attention = build_Bilstm4_model(seq_length=15, scale_factor=0.2, recent_scale=0.1)\n",
    "model_attention.summary()\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", patience=15, restore_best_weights=True, verbose=1)\n",
    "history = model_attention.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val), batch_size=8, callbacks=[early_stop], verbose=1)\n",
    "\n",
    "# ---------------------------\n",
    "# 7. Evaluate the Model\n",
    "# ---------------------------\n",
    "y_pred = model_attention.predict(X_test)\n",
    "# Predictions on test set\n",
    "##y_pred = model.predict(X_test)\n",
    "\n",
    "# Inverse transform predictions and actual values\n",
    "y_pred_inv = scaler_y.inverse_transform(y_pred)\n",
    "y_test_inv = scaler_y.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Inverse transform predictions and actual values\n",
    "y_pred_inv = scaler_y.inverse_transform(y_pred)\n",
    "y_test_inv = scaler_y.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Calculate Metrics\n",
    "r2 = r2_score(y_test_inv, y_pred_inv)\n",
    "mae = mean_absolute_error(y_test_inv, y_pred_inv)\n",
    "mse = mean_squared_error(y_test_inv, y_pred_inv)\n",
    "rmse = np.sqrt(mse)  # Root Mean Squared Error\n",
    "\n",
    "# Calculate the actual range of the test set\n",
    "actual_range = np.max(y_test_inv) - np.min(y_test_inv)\n",
    "\n",
    "# Compute Scaled Metrics\n",
    "mae_scaled = mae / actual_range\n",
    "mse_scaled = mse / (actual_range ** 2)\n",
    "rmse_scaled = rmse / actual_range\n",
    "\n",
    "# Explained Variance Score\n",
    "evs = explained_variance_score(y_test_inv, y_pred_inv)\n",
    "\n",
    "# Print the results\n",
    "print(f\"ðŸ“Š Final Results -\")\n",
    "print(f\"  RÂ²: {r2:.4f}\")\n",
    "print(f\"  MAE: {mae:.4f}, MAE Scaled: {mae_scaled:.4f}\")\n",
    "print(f\"  MSE: {mse:.4f}, MSE Scaled: {mse_scaled:.4f}\")\n",
    "print(f\"  RMSE: {rmse:.4f}, RMSE Scaled: {rmse_scaled:.4f}\")\n",
    "print(f\"  MAPE: {mean_absolute_percentage_error(y_test_inv, y_pred_inv) * 100:.2f}%\")\n",
    "print(f\"  EVS: {evs:.4f}\")\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot the first 100 points for better visibility\n",
    "num_points = min(100, len(y_test_inv))\n",
    "\n",
    "plt.plot(y_test_inv[:num_points], label=\"Actual\", linestyle=\"-\", linewidth=2, marker=\"o\", markersize=3, alpha=0.8)\n",
    "plt.plot(y_pred_inv[:num_points], label=\"Predicted\", linestyle=\"--\", linewidth=2, marker=\"x\", markersize=3, alpha=0.8)\n",
    "\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Stock Price\")\n",
    "plt.title(\"Actual vs Predicted Stock Prices (Zoomed In)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WXMQhM2sLUww"
   },
   "source": [
    "## Full Model â€“ 15â€‘Day + 7â€‘Day + 1â€‘Day Branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T14:39:15.541176Z",
     "iopub.status.busy": "2025-07-02T14:39:15.541000Z",
     "iopub.status.idle": "2025-07-02T14:42:19.207930Z",
     "shell.execute_reply": "2025-07-02T14:42:19.207232Z",
     "shell.execute_reply.started": "2025-07-02T14:39:15.541162Z"
    },
    "id": "IRnQ4rGdLUwx",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.layers import Multiply, Activation\n",
    "\n",
    "def build_Bilstm5_model(seq_length=15,n_features=n_features, scale_factor=0.2, recent_scale=0.1):\n",
    "    inputs = Input(shape=(seq_length, n_features))\n",
    "\n",
    "    # Full branch (15 days)\n",
    "    full_branch = Bidirectional(LSTM(128, return_sequences=False, dropout=0.2))(inputs)\n",
    "    full_branch = Dense(64, activation='relu')(full_branch)\n",
    "    long_term_return = Dense(1, activation='tanh')(full_branch)\n",
    "    long_term_return = Lambda(lambda x: x * scale_factor)(long_term_return)\n",
    "\n",
    "    # Recent branch (7 days)\n",
    "    recent_input = Lambda(lambda x: x[:, -7:, :])(inputs)\n",
    "    recent_branch = Bidirectional(LSTM(128, return_sequences=False, dropout=0.2))(recent_input)\n",
    "    recent_branch = Dense(64, activation='relu')(recent_branch)\n",
    "    mid_term_return = Dense(1, activation='tanh')(recent_branch)\n",
    "    mid_term_return = Lambda(lambda x: x * scale_factor)(mid_term_return)\n",
    "\n",
    "    # Very recent branch (1 day)\n",
    "    very_recent_input = Lambda(lambda x: x[:, -1:, :])(inputs)\n",
    "    very_recent_branch = Flatten()(very_recent_input)\n",
    "    very_recent_branch = Dense(32, activation='relu')(very_recent_branch)\n",
    "    short_term_return = Dense(1, activation='tanh')(very_recent_branch)\n",
    "    short_term_return = Lambda(lambda x: x * recent_scale)(short_term_return)\n",
    "\n",
    "    # Gating mechanisms\n",
    "    gate_7 = Dense(1, activation='sigmoid')(mid_term_return)\n",
    "    gate_1 = Dense(1, activation='sigmoid')(short_term_return)\n",
    "    gated_mid_term_return = Multiply()([mid_term_return, gate_7])\n",
    "    gated_short_term_return = Multiply()([short_term_return, gate_1])\n",
    "\n",
    "    # Fuse all branches\n",
    "    fused_returns = Add()([long_term_return, gated_mid_term_return, gated_short_term_return])\n",
    "    fused_returns = Dense(32, activation='relu')(fused_returns)\n",
    "    final_return = Dense(1, activation='tanh')(fused_returns)\n",
    "    final_return = Lambda(lambda x: x * scale_factor)(final_return)\n",
    "\n",
    "    last_day = Lambda(lambda x: tf.expand_dims(x[:, -1, 0], axis=-1))(inputs)\n",
    "    final_output = Lambda(lambda inputs: inputs[0] * (1 + inputs[1]))([last_day, final_return])\n",
    "\n",
    "    model = Model(inputs, final_output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "    return model\n",
    "\n",
    "# *Build the Modified Model with Gating*\n",
    "# model_gated = build_gated_multi_scale_model(seq_length=15, scale_factor=0.2, recent_scale=0.1)\n",
    "# model_gated.summary()\n",
    "\n",
    "# *Build the Modified Model with Attention-Based Residuals*\n",
    "model_attention = build_Bilstm5_model(seq_length=15, scale_factor=0.2, recent_scale=0.1)\n",
    "model_attention.summary()\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", patience=15, restore_best_weights=True, verbose=1)\n",
    "history = model_attention.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val), batch_size=8, callbacks=[early_stop], verbose=1)\n",
    "\n",
    "# ---------------------------\n",
    "# 7. Evaluate the Model\n",
    "# ---------------------------\n",
    "y_pred = model_attention.predict(X_test)\n",
    "# Predictions on test set\n",
    "##y_pred = model.predict(X_test)\n",
    "\n",
    "# Inverse transform predictions and actual values\n",
    "y_pred_inv = scaler_y.inverse_transform(y_pred)\n",
    "y_test_inv = scaler_y.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Inverse transform predictions and actual values\n",
    "y_pred_inv = scaler_y.inverse_transform(y_pred)\n",
    "y_test_inv = scaler_y.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Calculate Metrics\n",
    "r2 = r2_score(y_test_inv, y_pred_inv)\n",
    "mae = mean_absolute_error(y_test_inv, y_pred_inv)\n",
    "mse = mean_squared_error(y_test_inv, y_pred_inv)\n",
    "rmse = np.sqrt(mse)  # Root Mean Squared Error\n",
    "\n",
    "# Calculate the actual range of the test set\n",
    "actual_range = np.max(y_test_inv) - np.min(y_test_inv)\n",
    "\n",
    "# Compute Scaled Metrics\n",
    "mae_scaled = mae / actual_range\n",
    "mse_scaled = mse / (actual_range ** 2)\n",
    "rmse_scaled = rmse / actual_range\n",
    "\n",
    "# Explained Variance Score\n",
    "evs = explained_variance_score(y_test_inv, y_pred_inv)\n",
    "\n",
    "# Print the results\n",
    "print(f\"ðŸ“Š Final Results -\")\n",
    "print(f\"  RÂ²: {r2:.4f}\")\n",
    "print(f\"  MAE: {mae:.4f}, MAE Scaled: {mae_scaled:.4f}\")\n",
    "print(f\"  MSE: {mse:.4f}, MSE Scaled: {mse_scaled:.4f}\")\n",
    "print(f\"  RMSE: {rmse:.4f}, RMSE Scaled: {rmse_scaled:.4f}\")\n",
    "print(f\"  MAPE: {mean_absolute_percentage_error(y_test_inv, y_pred_inv) * 100:.2f}%\")\n",
    "print(f\"  EVS: {evs:.4f}\")\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot the first 100 points for better visibility\n",
    "num_points = min(100, len(y_test_inv))\n",
    "\n",
    "plt.plot(y_test_inv[:num_points], label=\"Actual\", linestyle=\"-\", linewidth=2, marker=\"o\", markersize=3, alpha=0.8)\n",
    "plt.plot(y_pred_inv[:num_points], label=\"Predicted\", linestyle=\"--\", linewidth=2, marker=\"x\", markersize=3, alpha=0.8)\n",
    "\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Stock Price\")\n",
    "plt.title(\"Actual vs Predicted Stock Prices (Zoomed In)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u0zlArK-LUwx"
   },
   "source": [
    "# OUR RANGE: NIFTY50 (15-3-2008 to 15-3-2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T14:42:19.208820Z",
     "iopub.status.busy": "2025-07-02T14:42:19.208637Z",
     "iopub.status.idle": "2025-07-02T14:42:19.286768Z",
     "shell.execute_reply": "2025-07-02T14:42:19.286015Z",
     "shell.execute_reply.started": "2025-07-02T14:42:19.208805Z"
    },
    "id": "oeoc5bcDLUwx",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "vix = pd.read_csv(\"/kaggle/input/our-data-15-3-2008-to-15-3-2024/India VIX Historical Data (3).csv\")\n",
    "vix.drop(\"Vol.\",axis=1,inplace=True)\n",
    "vix[\"Change %\"] = vix[\"Change %\"].str.replace(\"%\", \"\").astype(float)\n",
    "vix.head(),vix.dtypes\n",
    "data=pd.read_csv(\"/kaggle/input/our-data-15-3-2008-to-15-3-2024/Nifty 50 Historical Data (2).csv\")\n",
    "data=data[::-1]\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "data.head()\n",
    "data.nunique()\n",
    "\n",
    "data.sort_index(axis=1,ascending=True)\n",
    "data.rename(columns={'Price': 'Close'}, inplace=True)\n",
    "df = data.copy()  # Ensure we don't modify the original dataset\n",
    "\n",
    "# Convert financial columns to numeric (remove commas)\n",
    "for col in [\"Close\", \"Open\", \"High\", \"Low\"]:\n",
    "    df[col] = df[col].astype(str).str.replace(\",\", \"\").astype(float)\n",
    "\n",
    "# Function to convert 'Vol.' column\n",
    "def convert_volume(vol):\n",
    "    if isinstance(vol, str):  # Ensure it's a string before replacing\n",
    "        vol = vol.replace(\",\", \"\")  # Remove any thousand separators\n",
    "        if \"B\" in vol:\n",
    "            return float(vol.replace(\"B\", \"\")) * 1_000_000_000\n",
    "        elif \"M\" in vol:\n",
    "            return float(vol.replace(\"M\", \"\")) * 1_000_000\n",
    "        elif \"K\" in vol:\n",
    "            return float(vol.replace(\"K\", \"\")) * 1_000\n",
    "    return float(vol)  # Convert directly if already a number\n",
    "\n",
    "df[\"Vol.\"] = df[\"Vol.\"].astype(str).apply(convert_volume)\n",
    "\n",
    "# Convert 'Change %' column (remove '%' and convert to float)\n",
    "df[\"Change %\"] = df[\"Change %\"].astype(str).str.replace(\"%\", \"\").astype(float)\n",
    "\n",
    "# Print final DataFrame\n",
    "print(df.dtypes)\n",
    "print(df)\n",
    "\n",
    "# Assign back to 'data' (if needed)\n",
    "data = df\n",
    "\n",
    "#data = pd.merge(data, vix, on='Date', how='inner')\n",
    "data.drop(['Date'], axis=1, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T14:45:45.010432Z",
     "iopub.status.busy": "2025-07-02T14:45:45.010133Z",
     "iopub.status.idle": "2025-07-02T14:45:45.051833Z",
     "shell.execute_reply": "2025-07-02T14:45:45.051246Z",
     "shell.execute_reply.started": "2025-07-02T14:45:45.010411Z"
    },
    "id": "5hKcqosRLUwy",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, mean_absolute_percentage_error, explained_variance_score\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Input, Dense, Bidirectional, LSTM, Lambda, Concatenate, Add, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# ---------------------------\n",
    "# 1. Set Seed for Reproducibility\n",
    "# ---------------------------\n",
    "def set_random_seed(seed=20):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    tf.config.experimental.enable_op_determinism()\n",
    "\n",
    "set_random_seed(20)\n",
    "\n",
    "# ---------------------------\n",
    "# 2. Load & Preprocess Data\n",
    "# ---------------------------\n",
    "# For demonstration, we use a basic univariate \"Close\" series.\n",
    "# Ensure that your DataFrame 'data' contains at least a \"Close\" column.\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# ---------------------------\n",
    "# 2. Load & Preprocess Data\n",
    "# ---------------------------\n",
    "# Separate features (X) and target (y)\n",
    "data.dropna(axis=0,inplace=True)\n",
    "y = data[['Close']].copy()\n",
    "X = data.drop('Close', axis=1).copy()\n",
    "\n",
    "# It's important to scale your features and target separately.\n",
    "# We'll need the 'scaler_y' later to inverse the transformation of our predictions.\n",
    "scaler_X = MinMaxScaler()\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "\n",
    "scaler_y = MinMaxScaler()\n",
    "y_scaled = scaler_y.fit_transform(y)\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# 3. Create 15-day Sequences for Multivariate Data\n",
    "# ---------------------------\n",
    "def create_multivariate_sequences(X_data, y_data, time_steps=15):\n",
    "    \"\"\"\n",
    "    Creates sequences for multivariate time series data.\n",
    "    \"\"\"\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X_data) - time_steps):\n",
    "        # Get a sequence of 'time_steps' from the features\n",
    "        Xs.append(X_data[i:(i + time_steps)])\n",
    "        # The target is the 'Close' price at the end of the sequence\n",
    "        ys.append(y_data[i + time_steps])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "\n",
    "# Create the sequences\n",
    "X_seq, y_seq = create_multivariate_sequences(X_scaled, y_scaled, time_steps=15)\n",
    "\n",
    "# Split the data into training, validation, and testing sets\n",
    "train_size = int(len(X_seq) * 0.7)\n",
    "val_size = int(len(X_seq) * 0.1)\n",
    "\n",
    "X_train, y_train = X_seq[:train_size], y_seq[:train_size]\n",
    "X_val, y_val = X_seq[train_size:train_size + val_size], y_seq[train_size:train_size + val_size]\n",
    "X_test, y_test = X_seq[train_size + val_size:], y_seq[train_size + val_size:]\n",
    "\n",
    "# The input for the model will have a shape of (number of samples, timesteps, number of features)\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "n_features = X.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x86Sc0fFLUwy"
   },
   "source": [
    "## with single LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T14:45:45.053783Z",
     "iopub.status.busy": "2025-07-02T14:45:45.053084Z",
     "iopub.status.idle": "2025-07-02T14:46:28.639284Z",
     "shell.execute_reply": "2025-07-02T14:46:28.638616Z",
     "shell.execute_reply.started": "2025-07-02T14:45:45.053759Z"
    },
    "id": "tiMeKHDRLUwy",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.layers import Multiply, Activation\n",
    "\n",
    "def build_lstm_model(seq_length=15,n_features=n_features, scale_factor=0.2, recent_scale=0.1):\n",
    "    inputs = Input(shape=(seq_length, n_features))\n",
    "    # Simple LSTM (unidirectional)\n",
    "    x = LSTM(128, return_sequences=False, dropout=0.2)(inputs)\n",
    "    x = Dense(16)(x)\n",
    "    x = Dense(1,activation=\"tanh\")(x)\n",
    "    x = Lambda(lambda x: x * scale_factor)(x)\n",
    "\n",
    "    # Use the last day's price for final output calculation\n",
    "    last_day = Lambda(lambda x: tf.expand_dims(x[:, -1, 0], axis=-1))(inputs)\n",
    "    final_output = Lambda(lambda inputs: inputs[0] * (1 + inputs[1]))([last_day, x])\n",
    "\n",
    "    model = Model(inputs, final_output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "    return model\n",
    "\n",
    "# *Build the Modified Model with Gating*\n",
    "# model_gated = build_gated_multi_scale_model(seq_length=15, scale_factor=0.2, recent_scale=0.1)\n",
    "# model_gated.summary()\n",
    "\n",
    "# *Build the Modified Model with Attention-Based Residuals*\n",
    "model_attention = build_lstm_model(seq_length=15, scale_factor=0.2, recent_scale=0.1)\n",
    "model_attention.summary()\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", patience=15, restore_best_weights=True, verbose=1)\n",
    "history = model_attention.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val), batch_size=8, callbacks=[early_stop], verbose=1)\n",
    "\n",
    "# ---------------------------\n",
    "# 7. Evaluate the Model\n",
    "# ---------------------------\n",
    "y_pred = model_attention.predict(X_test)\n",
    "# Predictions on test set\n",
    "##y_pred = model.predict(X_test)\n",
    "\n",
    "# Inverse transform predictions and actual values\n",
    "y_pred_inv = scaler_y.inverse_transform(y_pred)\n",
    "y_test_inv = scaler_y.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Inverse transform predictions and actual values\n",
    "y_pred_inv = scaler_y.inverse_transform(y_pred)\n",
    "y_test_inv = scaler_y.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Calculate Metrics\n",
    "r2 = r2_score(y_test_inv, y_pred_inv)\n",
    "mae = mean_absolute_error(y_test_inv, y_pred_inv)\n",
    "mse = mean_squared_error(y_test_inv, y_pred_inv)\n",
    "rmse = np.sqrt(mse)  # Root Mean Squared Error\n",
    "\n",
    "# Calculate the actual range of the test set\n",
    "actual_range = np.max(y_test_inv) - np.min(y_test_inv)\n",
    "\n",
    "# Compute Scaled Metrics\n",
    "mae_scaled = mae / actual_range\n",
    "mse_scaled = mse / (actual_range ** 2)\n",
    "rmse_scaled = rmse / actual_range\n",
    "\n",
    "# Explained Variance Score\n",
    "evs = explained_variance_score(y_test_inv, y_pred_inv)\n",
    "\n",
    "# Print the results\n",
    "print(f\"ðŸ“Š Final Results -\")\n",
    "print(f\"  RÂ²: {r2:.4f}\")\n",
    "print(f\"  MAE: {mae:.4f}, MAE Scaled: {mae_scaled:.4f}\")\n",
    "print(f\"  MSE: {mse:.4f}, MSE Scaled: {mse_scaled:.4f}\")\n",
    "print(f\"  RMSE: {rmse:.4f}, RMSE Scaled: {rmse_scaled:.4f}\")\n",
    "print(f\"  MAPE: {mean_absolute_percentage_error(y_test_inv, y_pred_inv) * 100:.2f}%\")\n",
    "print(f\"  EVS: {evs:.4f}\")\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot the first 100 points for better visibility\n",
    "num_points = min(100, len(y_test_inv))\n",
    "\n",
    "plt.plot(y_test_inv[:num_points], label=\"Actual\", linestyle=\"-\", linewidth=2, marker=\"o\", markersize=3, alpha=0.8)\n",
    "plt.plot(y_pred_inv[:num_points], label=\"Predicted\", linestyle=\"--\", linewidth=2, marker=\"x\", markersize=3, alpha=0.8)\n",
    "\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Stock Price\")\n",
    "plt.title(\"Actual vs Predicted Stock Prices (Zoomed In)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T14:46:28.640190Z",
     "iopub.status.busy": "2025-07-02T14:46:28.640005Z",
     "iopub.status.idle": "2025-07-02T14:46:28.706467Z",
     "shell.execute_reply": "2025-07-02T14:46:28.705948Z",
     "shell.execute_reply.started": "2025-07-02T14:46:28.640176Z"
    },
    "id": "cEBNj4x2LUwy",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "vix = pd.read_csv(\"/kaggle/input/our-data-15-3-2008-to-15-3-2024/India VIX Historical Data (3).csv\")\n",
    "vix.drop(\"Vol.\",axis=1,inplace=True)\n",
    "vix[\"Change %\"] = vix[\"Change %\"].str.replace(\"%\", \"\").astype(float)\n",
    "vix.head(),vix.dtypes\n",
    "data=pd.read_csv(\"/kaggle/input/our-data-15-3-2008-to-15-3-2024/Nifty 50 Historical Data (2).csv\")\n",
    "data=data[::-1]\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "data.head()\n",
    "data.nunique()\n",
    "\n",
    "data.sort_index(axis=1,ascending=True)\n",
    "data.rename(columns={'Price': 'Close'}, inplace=True)\n",
    "df = data.copy()  # Ensure we don't modify the original dataset\n",
    "\n",
    "# Convert financial columns to numeric (remove commas)\n",
    "for col in [\"Close\", \"Open\", \"High\", \"Low\"]:\n",
    "    df[col] = df[col].astype(str).str.replace(\",\", \"\").astype(float)\n",
    "\n",
    "# Function to convert 'Vol.' column\n",
    "def convert_volume(vol):\n",
    "    if isinstance(vol, str):  # Ensure it's a string before replacing\n",
    "        vol = vol.replace(\",\", \"\")  # Remove any thousand separators\n",
    "        if \"B\" in vol:\n",
    "            return float(vol.replace(\"B\", \"\")) * 1_000_000_000\n",
    "        elif \"M\" in vol:\n",
    "            return float(vol.replace(\"M\", \"\")) * 1_000_000\n",
    "        elif \"K\" in vol:\n",
    "            return float(vol.replace(\"K\", \"\")) * 1_000\n",
    "    return float(vol)  # Convert directly if already a number\n",
    "\n",
    "df[\"Vol.\"] = df[\"Vol.\"].astype(str).apply(convert_volume)\n",
    "\n",
    "# Convert 'Change %' column (remove '%' and convert to float)\n",
    "df[\"Change %\"] = df[\"Change %\"].astype(str).str.replace(\"%\", \"\").astype(float)\n",
    "\n",
    "# Print final DataFrame\n",
    "print(df.dtypes)\n",
    "print(df)\n",
    "\n",
    "# Assign back to 'data' (if needed)\n",
    "data = df\n",
    "\n",
    "data = pd.merge(data, vix, on='Date', how='inner')\n",
    "data.drop(['Date'], axis=1, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T14:48:40.955341Z",
     "iopub.status.busy": "2025-07-02T14:48:40.954605Z",
     "iopub.status.idle": "2025-07-02T14:48:40.994196Z",
     "shell.execute_reply": "2025-07-02T14:48:40.993607Z",
     "shell.execute_reply.started": "2025-07-02T14:48:40.955317Z"
    },
    "id": "d0YJslFpLUwy",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, mean_absolute_percentage_error, explained_variance_score\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Input, Dense, Bidirectional, LSTM, Lambda, Concatenate, Add, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# ---------------------------\n",
    "# 1. Set Seed for Reproducibility\n",
    "# ---------------------------\n",
    "def set_random_seed(seed=20):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    tf.config.experimental.enable_op_determinism()\n",
    "\n",
    "set_random_seed(20)\n",
    "\n",
    "# ---------------------------\n",
    "# 2. Load & Preprocess Data\n",
    "# ---------------------------\n",
    "# For demonstration, we use a basic univariate \"Close\" series.\n",
    "# Ensure that your DataFrame 'data' contains at least a \"Close\" column.\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# ---------------------------\n",
    "# 2. Load & Preprocess Data\n",
    "# ---------------------------\n",
    "# Separate features (X) and target (y)\n",
    "data.dropna(axis=0,inplace=True)\n",
    "y = data[['Close']].copy()\n",
    "X = data.drop('Close', axis=1).copy()\n",
    "\n",
    "# It's important to scale your features and target separately.\n",
    "# We'll need the 'scaler_y' later to inverse the transformation of our predictions.\n",
    "scaler_X = MinMaxScaler()\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "\n",
    "scaler_y = MinMaxScaler()\n",
    "y_scaled = scaler_y.fit_transform(y)\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# 3. Create 15-day Sequences for Multivariate Data\n",
    "# ---------------------------\n",
    "def create_multivariate_sequences(X_data, y_data, time_steps=15):\n",
    "    \"\"\"\n",
    "    Creates sequences for multivariate time series data.\n",
    "    \"\"\"\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X_data) - time_steps):\n",
    "        # Get a sequence of 'time_steps' from the features\n",
    "        Xs.append(X_data[i:(i + time_steps)])\n",
    "        # The target is the 'Close' price at the end of the sequence\n",
    "        ys.append(y_data[i + time_steps])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "\n",
    "# Create the sequences\n",
    "X_seq, y_seq = create_multivariate_sequences(X_scaled, y_scaled, time_steps=15)\n",
    "\n",
    "# Split the data into training, validation, and testing sets\n",
    "train_size = int(len(X_seq) * 0.7)\n",
    "val_size = int(len(X_seq) * 0.1)\n",
    "\n",
    "X_train, y_train = X_seq[:train_size], y_seq[:train_size]\n",
    "X_val, y_val = X_seq[train_size:train_size + val_size], y_seq[train_size:train_size + val_size]\n",
    "X_test, y_test = X_seq[train_size + val_size:], y_seq[train_size + val_size:]\n",
    "\n",
    "# The input for the model will have a shape of (number of samples, timesteps, number of features)\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "n_features = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T14:48:40.995413Z",
     "iopub.status.busy": "2025-07-02T14:48:40.995219Z",
     "iopub.status.idle": "2025-07-02T14:49:25.150243Z",
     "shell.execute_reply": "2025-07-02T14:49:25.149542Z",
     "shell.execute_reply.started": "2025-07-02T14:48:40.995397Z"
    },
    "id": "SCoFidWXLUwz",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.layers import Multiply, Activation\n",
    "\n",
    "def build_lstm_model(seq_length=15,n_features=n_features, scale_factor=0.2, recent_scale=0.1):\n",
    "    inputs = Input(shape=(seq_length, n_features))\n",
    "    # Simple LSTM (unidirectional)\n",
    "    x = LSTM(128, return_sequences=False, dropout=0.2)(inputs)\n",
    "    x = Dense(16)(x)\n",
    "    x = Dense(1,activation=\"tanh\")(x)\n",
    "    x = Lambda(lambda x: x * scale_factor)(x)\n",
    "\n",
    "    # Use the last day's price for final output calculation\n",
    "    last_day = Lambda(lambda x: tf.expand_dims(x[:, -1, 0], axis=-1))(inputs)\n",
    "    final_output = Lambda(lambda inputs: inputs[0] * (1 + inputs[1]))([last_day, x])\n",
    "\n",
    "    model = Model(inputs, final_output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "    return model\n",
    "\n",
    "# *Build the Modified Model with Gating*\n",
    "# model_gated = build_gated_multi_scale_model(seq_length=15, scale_factor=0.2, recent_scale=0.1)\n",
    "# model_gated.summary()\n",
    "\n",
    "# *Build the Modified Model with Attention-Based Residuals*\n",
    "model_attention = build_lstm_model(seq_length=15, scale_factor=0.2, recent_scale=0.1)\n",
    "model_attention.summary()\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", patience=15, restore_best_weights=True, verbose=1)\n",
    "history = model_attention.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val), batch_size=8, callbacks=[early_stop], verbose=1)\n",
    "\n",
    "# ---------------------------\n",
    "# 7. Evaluate the Model\n",
    "# ---------------------------\n",
    "y_pred = model_attention.predict(X_test)\n",
    "# Predictions on test set\n",
    "##y_pred = model.predict(X_test)\n",
    "\n",
    "# Inverse transform predictions and actual values\n",
    "y_pred_inv = scaler_y.inverse_transform(y_pred)\n",
    "y_test_inv = scaler_y.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Inverse transform predictions and actual values\n",
    "y_pred_inv = scaler_y.inverse_transform(y_pred)\n",
    "y_test_inv = scaler_y.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Calculate Metrics\n",
    "r2 = r2_score(y_test_inv, y_pred_inv)\n",
    "mae = mean_absolute_error(y_test_inv, y_pred_inv)\n",
    "mse = mean_squared_error(y_test_inv, y_pred_inv)\n",
    "rmse = np.sqrt(mse)  # Root Mean Squared Error\n",
    "\n",
    "# Calculate the actual range of the test set\n",
    "actual_range = np.max(y_test_inv) - np.min(y_test_inv)\n",
    "\n",
    "# Compute Scaled Metrics\n",
    "mae_scaled = mae / actual_range\n",
    "mse_scaled = mse / (actual_range ** 2)\n",
    "rmse_scaled = rmse / actual_range\n",
    "\n",
    "# Explained Variance Score\n",
    "evs = explained_variance_score(y_test_inv, y_pred_inv)\n",
    "\n",
    "# Print the results\n",
    "print(f\"ðŸ“Š Final Results -\")\n",
    "print(f\"  RÂ²: {r2:.4f}\")\n",
    "print(f\"  MAE: {mae:.4f}, MAE Scaled: {mae_scaled:.4f}\")\n",
    "print(f\"  MSE: {mse:.4f}, MSE Scaled: {mse_scaled:.4f}\")\n",
    "print(f\"  RMSE: {rmse:.4f}, RMSE Scaled: {rmse_scaled:.4f}\")\n",
    "print(f\"  MAPE: {mean_absolute_percentage_error(y_test_inv, y_pred_inv) * 100:.2f}%\")\n",
    "print(f\"  EVS: {evs:.4f}\")\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot the first 100 points for better visibility\n",
    "num_points = min(100, len(y_test_inv))\n",
    "\n",
    "plt.plot(y_test_inv[:num_points], label=\"Actual\", linestyle=\"-\", linewidth=2, marker=\"o\", markersize=3, alpha=0.8)\n",
    "plt.plot(y_pred_inv[:num_points], label=\"Predicted\", linestyle=\"--\", linewidth=2, marker=\"x\", markersize=3, alpha=0.8)\n",
    "\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Stock Price\")\n",
    "plt.title(\"Actual vs Predicted Stock Prices (Zoomed In)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5r80MJ_8LUwz"
   },
   "source": [
    "## 15-Day Branch with Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T14:49:25.151986Z",
     "iopub.status.busy": "2025-07-02T14:49:25.151682Z",
     "iopub.status.idle": "2025-07-02T14:50:11.707667Z",
     "shell.execute_reply": "2025-07-02T14:50:11.707030Z",
     "shell.execute_reply.started": "2025-07-02T14:49:25.151964Z"
    },
    "id": "7cXO6KHDLUwz",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Multiply, Activation\n",
    "\n",
    "def build_Bilstm1_model(seq_length=15,n_features=n_features, scale_factor=0.2, recent_scale=0.1):\n",
    "    inputs = Input(shape=(seq_length, n_features))\n",
    "    # 15-day full branch with BiLSTM\n",
    "    x = Bidirectional(LSTM(128, return_sequences=False, dropout=0.2))(inputs)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dense(1, activation='tanh')(x)\n",
    "    x = Lambda(lambda x: x * scale_factor)(x)\n",
    "\n",
    "    last_day = Lambda(lambda x: tf.expand_dims(x[:, -1, 0], axis=-1))(inputs)\n",
    "    final_output = Lambda(lambda inputs: inputs[0] * (1 + inputs[1]))([last_day, x])\n",
    "\n",
    "    model = Model(inputs, final_output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "    return model\n",
    "\n",
    "# *Build the Modified Model with Gating*\n",
    "# model_gated = build_gated_multi_scale_model(seq_length=15, scale_factor=0.2, recent_scale=0.1)\n",
    "# model_gated.summary()\n",
    "\n",
    "# *Build the Modified Model with Attention-Based Residuals*\n",
    "model_attention = build_Bilstm1_model(seq_length=15, scale_factor=0.2, recent_scale=0.1)\n",
    "model_attention.summary()\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", patience=15, restore_best_weights=True, verbose=1)\n",
    "history = model_attention.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val), batch_size=8, callbacks=[early_stop], verbose=1)\n",
    "\n",
    "# ---------------------------\n",
    "# 7. Evaluate the Model\n",
    "# ---------------------------\n",
    "y_pred = model_attention.predict(X_test)\n",
    "# Predictions on test set\n",
    "##y_pred = model.predict(X_test)\n",
    "\n",
    "# Inverse transform predictions and actual values\n",
    "y_pred_inv = scaler_y.inverse_transform(y_pred)\n",
    "y_test_inv = scaler_y.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Inverse transform predictions and actual values\n",
    "y_pred_inv = scaler_y.inverse_transform(y_pred)\n",
    "y_test_inv = scaler_y.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Calculate Metrics\n",
    "r2 = r2_score(y_test_inv, y_pred_inv)\n",
    "mae = mean_absolute_error(y_test_inv, y_pred_inv)\n",
    "mse = mean_squared_error(y_test_inv, y_pred_inv)\n",
    "rmse = np.sqrt(mse)  # Root Mean Squared Error\n",
    "\n",
    "# Calculate the actual range of the test set\n",
    "actual_range = np.max(y_test_inv) - np.min(y_test_inv)\n",
    "\n",
    "# Compute Scaled Metrics\n",
    "mae_scaled = mae / actual_range\n",
    "mse_scaled = mse / (actual_range ** 2)\n",
    "rmse_scaled = rmse / actual_range\n",
    "\n",
    "# Explained Variance Score\n",
    "evs = explained_variance_score(y_test_inv, y_pred_inv)\n",
    "\n",
    "# Print the results\n",
    "print(f\"ðŸ“Š Final Results -\")\n",
    "print(f\"  RÂ²: {r2:.4f}\")\n",
    "print(f\"  MAE: {mae:.4f}, MAE Scaled: {mae_scaled:.4f}\")\n",
    "print(f\"  MSE: {mse:.4f}, MSE Scaled: {mse_scaled:.4f}\")\n",
    "print(f\"  RMSE: {rmse:.4f}, RMSE Scaled: {rmse_scaled:.4f}\")\n",
    "print(f\"  MAPE: {mean_absolute_percentage_error(y_test_inv, y_pred_inv) * 100:.2f}%\")\n",
    "print(f\"  EVS: {evs:.4f}\")\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot the first 100 points for better visibility\n",
    "num_points = min(100, len(y_test_inv))\n",
    "\n",
    "plt.plot(y_test_inv[:num_points], label=\"Actual\", linestyle=\"-\", linewidth=2, marker=\"o\", markersize=3, alpha=0.8)\n",
    "plt.plot(y_pred_inv[:num_points], label=\"Predicted\", linestyle=\"--\", linewidth=2, marker=\"x\", markersize=3, alpha=0.8)\n",
    "\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Stock Price\")\n",
    "plt.title(\"Actual vs Predicted Stock Prices (Zoomed In)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XsuqiAP-LUw0"
   },
   "source": [
    "## 15-Day + 7-Day Branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T14:50:11.708954Z",
     "iopub.status.busy": "2025-07-02T14:50:11.708631Z",
     "iopub.status.idle": "2025-07-02T14:51:23.318485Z",
     "shell.execute_reply": "2025-07-02T14:51:23.317805Z",
     "shell.execute_reply.started": "2025-07-02T14:50:11.708909Z"
    },
    "id": "J6kOYJsQLUw0",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.layers import Multiply, Activation\n",
    "\n",
    "def build_Bilstm2_model(seq_length=15,n_features=n_features, scale_factor=0.2, recent_scale=0.1):\n",
    "    inputs = Input(shape=(seq_length, n_features))\n",
    "\n",
    "    # Full branch (15 days)\n",
    "    full_branch = Bidirectional(LSTM(128, return_sequences=False, dropout=0.2))(inputs)\n",
    "    full_branch = Dense(64, activation='relu')(full_branch)\n",
    "    long_term_return = Dense(1, activation='tanh')(full_branch)\n",
    "    long_term_return = Lambda(lambda x: x * scale_factor)(long_term_return)\n",
    "\n",
    "    # Recent branch (last 7 days)\n",
    "    recent_input = Lambda(lambda x: x[:, -7:, :])(inputs)\n",
    "    recent_branch = Bidirectional(LSTM(128, return_sequences=False, dropout=0.2))(recent_input)\n",
    "    recent_branch = Dense(64, activation='relu')(recent_branch)\n",
    "    mid_term_return = Dense(1, activation='tanh')(recent_branch)\n",
    "    mid_term_return = Lambda(lambda x: x * scale_factor)(mid_term_return)\n",
    "\n",
    "    # Gate the 7-day branch output\n",
    "    gate_7 = Dense(1, activation='sigmoid')(mid_term_return)\n",
    "    gated_mid_term_return = Multiply()([mid_term_return, gate_7])\n",
    "\n",
    "    # Fuse the two branches\n",
    "    fused_returns = Add()([long_term_return, gated_mid_term_return])\n",
    "    fused_returns = Dense(32, activation='relu')(fused_returns)\n",
    "    final_return = Dense(1, activation='tanh')(fused_returns)\n",
    "    final_return = Lambda(lambda x: x * scale_factor)(final_return)\n",
    "\n",
    "    last_day = Lambda(lambda x: tf.expand_dims(x[:, -1, 0], axis=-1))(inputs)\n",
    "    final_output = Lambda(lambda inputs: inputs[0] * (1 + inputs[1]))([last_day, final_return])\n",
    "\n",
    "    model = Model(inputs, final_output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "    return model\n",
    "\n",
    "# *Build the Modified Model with Gating*\n",
    "# model_gated = build_gated_multi_scale_model(seq_length=15, scale_factor=0.2, recent_scale=0.1)\n",
    "# model_gated.summary()\n",
    "\n",
    "# *Build the Modified Model with Attention-Based Residuals*\n",
    "model_attention = build_Bilstm2_model(seq_length=15, scale_factor=0.2, recent_scale=0.1)\n",
    "model_attention.summary()\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", patience=15, restore_best_weights=True, verbose=1)\n",
    "history = model_attention.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val), batch_size=8, callbacks=[early_stop], verbose=1)\n",
    "\n",
    "# ---------------------------\n",
    "# 7. Evaluate the Model\n",
    "# ---------------------------\n",
    "y_pred = model_attention.predict(X_test)\n",
    "# Predictions on test set\n",
    "##y_pred = model.predict(X_test)\n",
    "\n",
    "# Inverse transform predictions and actual values\n",
    "y_pred_inv = scaler_y.inverse_transform(y_pred)\n",
    "y_test_inv = scaler_y.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Inverse transform predictions and actual values\n",
    "y_pred_inv = scaler_y.inverse_transform(y_pred)\n",
    "y_test_inv = scaler_y.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Calculate Metrics\n",
    "r2 = r2_score(y_test_inv, y_pred_inv)\n",
    "mae = mean_absolute_error(y_test_inv, y_pred_inv)\n",
    "mse = mean_squared_error(y_test_inv, y_pred_inv)\n",
    "rmse = np.sqrt(mse)  # Root Mean Squared Error\n",
    "\n",
    "# Calculate the actual range of the test set\n",
    "actual_range = np.max(y_test_inv) - np.min(y_test_inv)\n",
    "\n",
    "# Compute Scaled Metrics\n",
    "mae_scaled = mae / actual_range\n",
    "mse_scaled = mse / (actual_range ** 2)\n",
    "rmse_scaled = rmse / actual_range\n",
    "\n",
    "# Explained Variance Score\n",
    "evs = explained_variance_score(y_test_inv, y_pred_inv)\n",
    "\n",
    "# Print the results\n",
    "print(f\"ðŸ“Š Final Results -\")\n",
    "print(f\"  RÂ²: {r2:.4f}\")\n",
    "print(f\"  MAE: {mae:.4f}, MAE Scaled: {mae_scaled:.4f}\")\n",
    "print(f\"  MSE: {mse:.4f}, MSE Scaled: {mse_scaled:.4f}\")\n",
    "print(f\"  RMSE: {rmse:.4f}, RMSE Scaled: {rmse_scaled:.4f}\")\n",
    "print(f\"  MAPE: {mean_absolute_percentage_error(y_test_inv, y_pred_inv) * 100:.2f}%\")\n",
    "print(f\"  EVS: {evs:.4f}\")\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot the first 100 points for better visibility\n",
    "num_points = min(100, len(y_test_inv))\n",
    "\n",
    "plt.plot(y_test_inv[:num_points], label=\"Actual\", linestyle=\"-\", linewidth=2, marker=\"o\", markersize=3, alpha=0.8)\n",
    "plt.plot(y_pred_inv[:num_points], label=\"Predicted\", linestyle=\"--\", linewidth=2, marker=\"x\", markersize=3, alpha=0.8)\n",
    "\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Stock Price\")\n",
    "plt.title(\"Actual vs Predicted Stock Prices (Zoomed In)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e8fqKp6cLUw0"
   },
   "source": [
    "## 7-Day + 1-Day Branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T14:51:23.320524Z",
     "iopub.status.busy": "2025-07-02T14:51:23.320319Z",
     "iopub.status.idle": "2025-07-02T14:54:10.753730Z",
     "shell.execute_reply": "2025-07-02T14:54:10.752958Z",
     "shell.execute_reply.started": "2025-07-02T14:51:23.320508Z"
    },
    "id": "sPDytHaoLUw1",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.layers import Multiply, Activation\n",
    "\n",
    "def build_Bilstm3_model(seq_length=15,n_features=n_features, scale_factor=0.2, recent_scale=0.1):\n",
    "    inputs = Input(shape=(seq_length, n_features))\n",
    "\n",
    "    # Recent branch (last 7 days)\n",
    "    recent_input = Lambda(lambda x: x[:, -7:, :])(inputs)\n",
    "    recent_branch = Bidirectional(LSTM(128, return_sequences=False, dropout=0.2))(recent_input)\n",
    "    recent_branch = Dense(64, activation='relu')(recent_branch)\n",
    "    mid_term_return = Dense(1, activation='tanh')(recent_branch)\n",
    "    mid_term_return = Lambda(lambda x: x * scale_factor)(mid_term_return)\n",
    "\n",
    "    # Very recent branch (last 1 day)\n",
    "    very_recent_input = Lambda(lambda x: x[:, -1:, :])(inputs)\n",
    "    very_recent_branch = Flatten()(very_recent_input)\n",
    "    very_recent_branch = Dense(32, activation='relu')(very_recent_branch)\n",
    "    short_term_return = Dense(1, activation='tanh')(very_recent_branch)\n",
    "    short_term_return = Lambda(lambda x: x * recent_scale)(short_term_return)\n",
    "\n",
    "    # Gating mechanisms\n",
    "    gate_7 = Dense(1, activation='sigmoid')(mid_term_return)\n",
    "    gate_1 = Dense(1, activation='sigmoid')(short_term_return)\n",
    "    gated_mid_term_return = Multiply()([mid_term_return, gate_7])\n",
    "    gated_short_term_return = Multiply()([short_term_return, gate_1])\n",
    "\n",
    "    # Combine gated outputs\n",
    "    fused_returns = Add()([gated_mid_term_return, gated_short_term_return])\n",
    "    fused_returns = Dense(32, activation='relu')(fused_returns)\n",
    "    final_return = Dense(1, activation='tanh')(fused_returns)\n",
    "    final_return = Lambda(lambda x: x * scale_factor)(final_return)\n",
    "\n",
    "    last_day = Lambda(lambda x: tf.expand_dims(x[:, -1, 0], axis=-1))(inputs)\n",
    "    final_output = Lambda(lambda inputs: inputs[0] * (1 + inputs[1]))([last_day, final_return])\n",
    "\n",
    "    model = Model(inputs, final_output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "    return model\n",
    "\n",
    "# *Build the Modified Model with Gating*\n",
    "# model_gated = build_gated_multi_scale_model(seq_length=15, scale_factor=0.2, recent_scale=0.1)\n",
    "# model_gated.summary()\n",
    "\n",
    "# *Build the Modified Model with Attention-Based Residuals*\n",
    "model_attention = build_Bilstm3_model(seq_length=15, scale_factor=0.2, recent_scale=0.1)\n",
    "model_attention.summary()\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", patience=15, restore_best_weights=True, verbose=1)\n",
    "history = model_attention.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val), batch_size=8, callbacks=[early_stop], verbose=1)\n",
    "\n",
    "# ---------------------------\n",
    "# 7. Evaluate the Model\n",
    "# ---------------------------\n",
    "y_pred = model_attention.predict(X_test)\n",
    "# Predictions on test set\n",
    "##y_pred = model.predict(X_test)\n",
    "\n",
    "# Inverse transform predictions and actual values\n",
    "y_pred_inv = scaler_y.inverse_transform(y_pred)\n",
    "y_test_inv = scaler_y.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Inverse transform predictions and actual values\n",
    "y_pred_inv = scaler_y.inverse_transform(y_pred)\n",
    "y_test_inv = scaler_y.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Calculate Metrics\n",
    "r2 = r2_score(y_test_inv, y_pred_inv)\n",
    "mae = mean_absolute_error(y_test_inv, y_pred_inv)\n",
    "mse = mean_squared_error(y_test_inv, y_pred_inv)\n",
    "rmse = np.sqrt(mse)  # Root Mean Squared Error\n",
    "\n",
    "# Calculate the actual range of the test set\n",
    "actual_range = np.max(y_test_inv) - np.min(y_test_inv)\n",
    "\n",
    "# Compute Scaled Metrics\n",
    "mae_scaled = mae / actual_range\n",
    "mse_scaled = mse / (actual_range ** 2)\n",
    "rmse_scaled = rmse / actual_range\n",
    "\n",
    "# Explained Variance Score\n",
    "evs = explained_variance_score(y_test_inv, y_pred_inv)\n",
    "\n",
    "# Print the results\n",
    "print(f\"ðŸ“Š Final Results -\")\n",
    "print(f\"  RÂ²: {r2:.4f}\")\n",
    "print(f\"  MAE: {mae:.4f}, MAE Scaled: {mae_scaled:.4f}\")\n",
    "print(f\"  MSE: {mse:.4f}, MSE Scaled: {mse_scaled:.4f}\")\n",
    "print(f\"  RMSE: {rmse:.4f}, RMSE Scaled: {rmse_scaled:.4f}\")\n",
    "print(f\"  MAPE: {mean_absolute_percentage_error(y_test_inv, y_pred_inv) * 100:.2f}%\")\n",
    "print(f\"  EVS: {evs:.4f}\")\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot the first 100 points for better visibility\n",
    "num_points = min(100, len(y_test_inv))\n",
    "\n",
    "plt.plot(y_test_inv[:num_points], label=\"Actual\", linestyle=\"-\", linewidth=2, marker=\"o\", markersize=3, alpha=0.8)\n",
    "plt.plot(y_pred_inv[:num_points], label=\"Predicted\", linestyle=\"--\", linewidth=2, marker=\"x\", markersize=3, alpha=0.8)\n",
    "\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Stock Price\")\n",
    "plt.title(\"Actual vs Predicted Stock Prices (Zoomed In)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fy02VEGNLUw1"
   },
   "source": [
    "## 15-Day + 1-Day Branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T14:54:10.754749Z",
     "iopub.status.busy": "2025-07-02T14:54:10.754495Z",
     "iopub.status.idle": "2025-07-02T14:56:17.434094Z",
     "shell.execute_reply": "2025-07-02T14:56:17.433372Z",
     "shell.execute_reply.started": "2025-07-02T14:54:10.754728Z"
    },
    "id": "QMf2DcKOLUw1",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.layers import Multiply, Activation\n",
    "\n",
    "def build_Bilstm4_model(seq_length=15,n_features=n_features, scale_factor=0.2, recent_scale=0.1):\n",
    "    inputs = Input(shape=(seq_length, n_features))\n",
    "\n",
    "    # Full branch (15 days)\n",
    "    full_branch = Bidirectional(LSTM(128, return_sequences=False, dropout=0.2))(inputs)\n",
    "    full_branch = Dense(64, activation='relu')(full_branch)\n",
    "    long_term_return = Dense(1, activation='tanh')(full_branch)\n",
    "    long_term_return = Lambda(lambda x: x * scale_factor)(long_term_return)\n",
    "\n",
    "    # Very recent branch (last 1 day)\n",
    "    very_recent_input = Lambda(lambda x: x[:, -1:, :])(inputs)\n",
    "    very_recent_branch = Flatten()(very_recent_input)\n",
    "    very_recent_branch = Dense(32, activation='relu')(very_recent_branch)\n",
    "    short_term_return = Dense(1, activation='tanh')(very_recent_branch)\n",
    "    short_term_return = Lambda(lambda x: x * recent_scale)(short_term_return)\n",
    "\n",
    "    # Gate the 1-day branch output\n",
    "    gate_1 = Dense(1, activation='sigmoid')(short_term_return)\n",
    "    gated_short_term_return = Multiply()([short_term_return, gate_1])\n",
    "\n",
    "    # Fuse branches\n",
    "    fused_returns = Add()([long_term_return, gated_short_term_return])\n",
    "    fused_returns = Dense(32, activation='relu')(fused_returns)\n",
    "    final_return = Dense(1, activation='tanh')(fused_returns)\n",
    "    final_return = Lambda(lambda x: x * scale_factor)(final_return)\n",
    "\n",
    "    last_day = Lambda(lambda x: tf.expand_dims(x[:, -1, 0], axis=-1))(inputs)\n",
    "    final_output = Lambda(lambda inputs: inputs[0] * (1 + inputs[1]))([last_day, final_return])\n",
    "\n",
    "    model = Model(inputs, final_output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "    return model\n",
    "\n",
    "# *Build the Modified Model with Gating*\n",
    "# model_gated = build_gated_multi_scale_model(seq_length=15, scale_factor=0.2, recent_scale=0.1)\n",
    "# model_gated.summary()\n",
    "\n",
    "# *Build the Modified Model with Attention-Based Residuals*\n",
    "model_attention = build_Bilstm4_model(seq_length=15, scale_factor=0.2, recent_scale=0.1)\n",
    "model_attention.summary()\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", patience=15, restore_best_weights=True, verbose=1)\n",
    "history = model_attention.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val), batch_size=8, callbacks=[early_stop], verbose=1)\n",
    "\n",
    "# ---------------------------\n",
    "# 7. Evaluate the Model\n",
    "# ---------------------------\n",
    "y_pred = model_attention.predict(X_test)\n",
    "# Predictions on test set\n",
    "##y_pred = model.predict(X_test)\n",
    "\n",
    "# Inverse transform predictions and actual values\n",
    "y_pred_inv = scaler_y.inverse_transform(y_pred)\n",
    "y_test_inv = scaler_y.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Inverse transform predictions and actual values\n",
    "y_pred_inv = scaler_y.inverse_transform(y_pred)\n",
    "y_test_inv = scaler_y.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Calculate Metrics\n",
    "r2 = r2_score(y_test_inv, y_pred_inv)\n",
    "mae = mean_absolute_error(y_test_inv, y_pred_inv)\n",
    "mse = mean_squared_error(y_test_inv, y_pred_inv)\n",
    "rmse = np.sqrt(mse)  # Root Mean Squared Error\n",
    "\n",
    "# Calculate the actual range of the test set\n",
    "actual_range = np.max(y_test_inv) - np.min(y_test_inv)\n",
    "\n",
    "# Compute Scaled Metrics\n",
    "mae_scaled = mae / actual_range\n",
    "mse_scaled = mse / (actual_range ** 2)\n",
    "rmse_scaled = rmse / actual_range\n",
    "\n",
    "# Explained Variance Score\n",
    "evs = explained_variance_score(y_test_inv, y_pred_inv)\n",
    "\n",
    "# Print the results\n",
    "print(f\"ðŸ“Š Final Results -\")\n",
    "print(f\"  RÂ²: {r2:.4f}\")\n",
    "print(f\"  MAE: {mae:.4f}, MAE Scaled: {mae_scaled:.4f}\")\n",
    "print(f\"  MSE: {mse:.4f}, MSE Scaled: {mse_scaled:.4f}\")\n",
    "print(f\"  RMSE: {rmse:.4f}, RMSE Scaled: {rmse_scaled:.4f}\")\n",
    "print(f\"  MAPE: {mean_absolute_percentage_error(y_test_inv, y_pred_inv) * 100:.2f}%\")\n",
    "print(f\"  EVS: {evs:.4f}\")\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot the first 100 points for better visibility\n",
    "num_points = min(100, len(y_test_inv))\n",
    "\n",
    "plt.plot(y_test_inv[:num_points], label=\"Actual\", linestyle=\"-\", linewidth=2, marker=\"o\", markersize=3, alpha=0.8)\n",
    "plt.plot(y_pred_inv[:num_points], label=\"Predicted\", linestyle=\"--\", linewidth=2, marker=\"x\", markersize=3, alpha=0.8)\n",
    "\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Stock Price\")\n",
    "plt.title(\"Actual vs Predicted Stock Prices (Zoomed In)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rmeLOZu5LUw2"
   },
   "source": [
    "## Full Model (15â€‘Day + 7â€‘Day + 1â€‘Day Branch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T14:56:17.435263Z",
     "iopub.status.busy": "2025-07-02T14:56:17.434968Z",
     "iopub.status.idle": "2025-07-02T14:56:17.508490Z",
     "shell.execute_reply": "2025-07-02T14:56:17.507944Z",
     "shell.execute_reply.started": "2025-07-02T14:56:17.435225Z"
    },
    "id": "rIfWpAUfLUw2",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "vix = pd.read_csv(\"/kaggle/input/our-data-15-3-2008-to-15-3-2024/India VIX Historical Data (3).csv\")\n",
    "vix.drop(\"Vol.\",axis=1,inplace=True)\n",
    "vix[\"Change %\"] = vix[\"Change %\"].str.replace(\"%\", \"\").astype(float)\n",
    "vix.head(),vix.dtypes\n",
    "data=pd.read_csv(\"/kaggle/input/our-data-15-3-2008-to-15-3-2024/Nifty 50 Historical Data (2).csv\")\n",
    "data=data[::-1]\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "data.head()\n",
    "data.nunique()\n",
    "\n",
    "data.sort_index(axis=1,ascending=True)\n",
    "data.rename(columns={'Price': 'Close'}, inplace=True)\n",
    "df = data.copy()  # Ensure we don't modify the original dataset\n",
    "\n",
    "# Convert financial columns to numeric (remove commas)\n",
    "for col in [\"Close\", \"Open\", \"High\", \"Low\"]:\n",
    "    df[col] = df[col].astype(str).str.replace(\",\", \"\").astype(float)\n",
    "\n",
    "# Function to convert 'Vol.' column\n",
    "def convert_volume(vol):\n",
    "    if isinstance(vol, str):  # Ensure it's a string before replacing\n",
    "        vol = vol.replace(\",\", \"\")  # Remove any thousand separators\n",
    "        if \"B\" in vol:\n",
    "            return float(vol.replace(\"B\", \"\")) * 1_000_000_000\n",
    "        elif \"M\" in vol:\n",
    "            return float(vol.replace(\"M\", \"\")) * 1_000_000\n",
    "        elif \"K\" in vol:\n",
    "            return float(vol.replace(\"K\", \"\")) * 1_000\n",
    "    return float(vol)  # Convert directly if already a number\n",
    "\n",
    "df[\"Vol.\"] = df[\"Vol.\"].astype(str).apply(convert_volume)\n",
    "\n",
    "# Convert 'Change %' column (remove '%' and convert to float)\n",
    "df[\"Change %\"] = df[\"Change %\"].astype(str).str.replace(\"%\", \"\").astype(float)\n",
    "\n",
    "# Print final DataFrame\n",
    "print(df.dtypes)\n",
    "print(df)\n",
    "\n",
    "# Assign back to 'data' (if needed)\n",
    "data = df\n",
    "\n",
    "data = pd.merge(data, vix, on='Date', how='inner')\n",
    "data.drop(['Date'], axis=1, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T15:00:57.965818Z",
     "iopub.status.busy": "2025-07-02T15:00:57.965532Z",
     "iopub.status.idle": "2025-07-02T15:00:58.024072Z",
     "shell.execute_reply": "2025-07-02T15:00:58.023465Z",
     "shell.execute_reply.started": "2025-07-02T15:00:57.965797Z"
    },
    "id": "Q64HjPaqLUw2",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, mean_absolute_percentage_error, explained_variance_score\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Input, Dense, Bidirectional, LSTM, Lambda, Concatenate, Add, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# ---------------------------\n",
    "# 1. Set Seed for Reproducibility\n",
    "# ---------------------------\n",
    "def set_random_seed(seed=20):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    tf.config.experimental.enable_op_determinism()\n",
    "\n",
    "set_random_seed(20)\n",
    "\n",
    "# ---------------------------\n",
    "# 2. Load & Preprocess Data\n",
    "# ---------------------------\n",
    "# For demonstration, we use a basic univariate \"Close\" series.\n",
    "# Ensure that your DataFrame 'data' contains at least a \"Close\" column.\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# ---------------------------\n",
    "# 2. Load & Preprocess Data\n",
    "# ---------------------------\n",
    "# Separate features (X) and target (y)\n",
    "data.dropna(axis=0,inplace=True)\n",
    "y = data[['Close']].copy()\n",
    "X = data.drop('Close', axis=1).copy()\n",
    "\n",
    "# It's important to scale your features and target separately.\n",
    "# We'll need the 'scaler_y' later to inverse the transformation of our predictions.\n",
    "scaler_X = MinMaxScaler()\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "\n",
    "scaler_y = MinMaxScaler()\n",
    "y_scaled = scaler_y.fit_transform(y)\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# 3. Create 15-day Sequences for Multivariate Data\n",
    "# ---------------------------\n",
    "def create_multivariate_sequences(X_data, y_data, time_steps=15):\n",
    "    \"\"\"\n",
    "    Creates sequences for multivariate time series data.\n",
    "    \"\"\"\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X_data) - time_steps):\n",
    "        # Get a sequence of 'time_steps' from the features\n",
    "        Xs.append(X_data[i:(i + time_steps)])\n",
    "        # The target is the 'Close' price at the end of the sequence\n",
    "        ys.append(y_data[i + time_steps])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "\n",
    "# Create the sequences\n",
    "X_seq, y_seq = create_multivariate_sequences(X_scaled, y_scaled, time_steps=15)\n",
    "\n",
    "# Split the data into training, validation, and testing sets\n",
    "train_size = int(len(X_seq) * 0.7)\n",
    "val_size = int(len(X_seq) * 0.1)\n",
    "\n",
    "X_train, y_train = X_seq[:train_size], y_seq[:train_size]\n",
    "X_val, y_val = X_seq[train_size:train_size + val_size], y_seq[train_size:train_size + val_size]\n",
    "X_test, y_test = X_seq[train_size + val_size:], y_seq[train_size + val_size:]\n",
    "\n",
    "# The input for the model will have a shape of (number of samples, timesteps, number of features)\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "n_features = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T15:01:02.601609Z",
     "iopub.status.busy": "2025-07-02T15:01:02.601344Z",
     "iopub.status.idle": "2025-07-02T15:02:25.866417Z",
     "shell.execute_reply": "2025-07-02T15:02:25.865688Z",
     "shell.execute_reply.started": "2025-07-02T15:01:02.601590Z"
    },
    "id": "xBl5NG-HLUw2",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.layers import Multiply, Activation\n",
    "\n",
    "def build_Bilstm5_model(seq_length=15,n_features=n_features, scale_factor=0.2, recent_scale=0.1):\n",
    "    inputs = Input(shape=(seq_length, n_features))\n",
    "\n",
    "    # Full branch (15 days)\n",
    "    full_branch = Bidirectional(LSTM(128, return_sequences=False, dropout=0.2))(inputs)\n",
    "    full_branch = Dense(64, activation='relu')(full_branch)\n",
    "    long_term_return = Dense(1, activation='tanh')(full_branch)\n",
    "    long_term_return = Lambda(lambda x: x * scale_factor)(long_term_return)\n",
    "\n",
    "    # Recent branch (7 days)\n",
    "    recent_input = Lambda(lambda x: x[:, -7:, :])(inputs)\n",
    "    recent_branch = Bidirectional(LSTM(128, return_sequences=False, dropout=0.2))(recent_input)\n",
    "    recent_branch = Dense(64, activation='relu')(recent_branch)\n",
    "    mid_term_return = Dense(1, activation='tanh')(recent_branch)\n",
    "    mid_term_return = Lambda(lambda x: x * scale_factor)(mid_term_return)\n",
    "\n",
    "    # Very recent branch (1 day)\n",
    "    very_recent_input = Lambda(lambda x: x[:, -1:, :])(inputs)\n",
    "    very_recent_branch = Flatten()(very_recent_input)\n",
    "    very_recent_branch = Dense(32, activation='relu')(very_recent_branch)\n",
    "    short_term_return = Dense(1, activation='tanh')(very_recent_branch)\n",
    "    short_term_return = Lambda(lambda x: x * recent_scale)(short_term_return)\n",
    "\n",
    "    # Gating mechanisms\n",
    "    gate_7 = Dense(1, activation='sigmoid')(mid_term_return)\n",
    "    gate_1 = Dense(1, activation='sigmoid')(short_term_return)\n",
    "    gated_mid_term_return = Multiply()([mid_term_return, gate_7])\n",
    "    gated_short_term_return = Multiply()([short_term_return, gate_1])\n",
    "\n",
    "    # Fuse all branches\n",
    "    fused_returns = Add()([long_term_return, gated_mid_term_return, gated_short_term_return])\n",
    "    fused_returns = Dense(32, activation='relu')(fused_returns)\n",
    "    final_return = Dense(1, activation='tanh')(fused_returns)\n",
    "    final_return = Lambda(lambda x: x * scale_factor)(final_return)\n",
    "\n",
    "    last_day = Lambda(lambda x: tf.expand_dims(x[:, -1, 0], axis=-1))(inputs)\n",
    "    final_output = Lambda(lambda inputs: inputs[0] * (1 + inputs[1]))([last_day, final_return])\n",
    "\n",
    "    model = Model(inputs, final_output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "    return model\n",
    "\n",
    "# *Build the Modified Model with Gating*\n",
    "# model_gated = build_gated_multi_scale_model(seq_length=15, scale_factor=0.2, recent_scale=0.1)\n",
    "# model_gated.summary()\n",
    "\n",
    "# *Build the Modified Model with Attention-Based Residuals*\n",
    "model_attention = build_Bilstm5_model(seq_length=15, scale_factor=0.2, recent_scale=0.1)\n",
    "model_attention.summary()\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", patience=15, restore_best_weights=True, verbose=1)\n",
    "history = model_attention.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val), batch_size=8, callbacks=[early_stop], verbose=1)\n",
    "\n",
    "# ---------------------------\n",
    "# 7. Evaluate the Model\n",
    "# ---------------------------\n",
    "y_pred = model_attention.predict(X_test)\n",
    "# Predictions on test set\n",
    "##y_pred = model.predict(X_test)\n",
    "\n",
    "# Inverse transform predictions and actual values\n",
    "y_pred_inv = scaler_y.inverse_transform(y_pred)\n",
    "y_test_inv = scaler_y.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Inverse transform predictions and actual values\n",
    "y_pred_inv = scaler_y.inverse_transform(y_pred)\n",
    "y_test_inv = scaler_y.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Calculate Metrics\n",
    "r2 = r2_score(y_test_inv, y_pred_inv)\n",
    "mae = mean_absolute_error(y_test_inv, y_pred_inv)\n",
    "mse = mean_squared_error(y_test_inv, y_pred_inv)\n",
    "rmse = np.sqrt(mse)  # Root Mean Squared Error\n",
    "\n",
    "# Calculate the actual range of the test set\n",
    "actual_range = np.max(y_test_inv) - np.min(y_test_inv)\n",
    "\n",
    "# Compute Scaled Metrics\n",
    "mae_scaled = mae / actual_range\n",
    "mse_scaled = mse / (actual_range ** 2)\n",
    "rmse_scaled = rmse / actual_range\n",
    "\n",
    "# Explained Variance Score\n",
    "evs = explained_variance_score(y_test_inv, y_pred_inv)\n",
    "\n",
    "# Print the results\n",
    "print(f\"ðŸ“Š Final Results -\")\n",
    "print(f\"  RÂ²: {r2:.4f}\")\n",
    "print(f\"  MAE: {mae:.4f}, MAE Scaled: {mae_scaled:.4f}\")\n",
    "print(f\"  MSE: {mse:.4f}, MSE Scaled: {mse_scaled:.4f}\")\n",
    "print(f\"  RMSE: {rmse:.4f}, RMSE Scaled: {rmse_scaled:.4f}\")\n",
    "print(f\"  MAPE: {mean_absolute_percentage_error(y_test_inv, y_pred_inv) * 100:.2f}%\")\n",
    "print(f\"  EVS: {evs:.4f}\")\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot the first 100 points for better visibility\n",
    "num_points = min(100, len(y_test_inv))\n",
    "\n",
    "plt.plot(y_test_inv[:num_points], label=\"Actual\", linestyle=\"-\", linewidth=2, marker=\"o\", markersize=3, alpha=0.8)\n",
    "plt.plot(y_pred_inv[:num_points], label=\"Predicted\", linestyle=\"--\", linewidth=2, marker=\"x\", markersize=3, alpha=0.8)\n",
    "\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Stock Price\")\n",
    "plt.title(\"Actual vs Predicted Stock Prices (Zoomed In)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T15:02:25.868028Z",
     "iopub.status.busy": "2025-07-02T15:02:25.867791Z",
     "iopub.status.idle": "2025-07-02T15:02:25.935769Z",
     "shell.execute_reply": "2025-07-02T15:02:25.935210Z",
     "shell.execute_reply.started": "2025-07-02T15:02:25.868011Z"
    },
    "id": "PQINWjFHLUw3",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "vix = pd.read_csv(\"/kaggle/input/our-data-15-3-2008-to-15-3-2024/India VIX Historical Data (3).csv\")\n",
    "vix.drop(\"Vol.\",axis=1,inplace=True)\n",
    "vix[\"Change %\"] = vix[\"Change %\"].str.replace(\"%\", \"\").astype(float)\n",
    "vix.head(),vix.dtypes\n",
    "data=pd.read_csv(\"/kaggle/input/our-data-15-3-2008-to-15-3-2024/Nifty 50 Historical Data (2).csv\")\n",
    "data=data[::-1]\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "data.head()\n",
    "data.nunique()\n",
    "\n",
    "data.sort_index(axis=1,ascending=True)\n",
    "data.rename(columns={'Price': 'Close'}, inplace=True)\n",
    "df = data.copy()  # Ensure we don't modify the original dataset\n",
    "\n",
    "# Convert financial columns to numeric (remove commas)\n",
    "for col in [\"Close\", \"Open\", \"High\", \"Low\"]:\n",
    "    df[col] = df[col].astype(str).str.replace(\",\", \"\").astype(float)\n",
    "\n",
    "# Function to convert 'Vol.' column\n",
    "def convert_volume(vol):\n",
    "    if isinstance(vol, str):  # Ensure it's a string before replacing\n",
    "        vol = vol.replace(\",\", \"\")  # Remove any thousand separators\n",
    "        if \"B\" in vol:\n",
    "            return float(vol.replace(\"B\", \"\")) * 1_000_000_000\n",
    "        elif \"M\" in vol:\n",
    "            return float(vol.replace(\"M\", \"\")) * 1_000_000\n",
    "        elif \"K\" in vol:\n",
    "            return float(vol.replace(\"K\", \"\")) * 1_000\n",
    "    return float(vol)  # Convert directly if already a number\n",
    "\n",
    "df[\"Vol.\"] = df[\"Vol.\"].astype(str).apply(convert_volume)\n",
    "\n",
    "# Convert 'Change %' column (remove '%' and convert to float)\n",
    "df[\"Change %\"] = df[\"Change %\"].astype(str).str.replace(\"%\", \"\").astype(float)\n",
    "\n",
    "# Print final DataFrame\n",
    "print(df.dtypes)\n",
    "print(df)\n",
    "\n",
    "# Assign back to 'data' (if needed)\n",
    "data = df\n",
    "\n",
    "#data = pd.merge(data, vix, on='Date', how='inner')\n",
    "data.drop(['Date'], axis=1, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T15:09:16.627264Z",
     "iopub.status.busy": "2025-07-02T15:09:16.627011Z",
     "iopub.status.idle": "2025-07-02T15:09:16.687303Z",
     "shell.execute_reply": "2025-07-02T15:09:16.686458Z",
     "shell.execute_reply.started": "2025-07-02T15:09:16.627248Z"
    },
    "id": "eRfl9zlmLUw3",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, mean_absolute_percentage_error, explained_variance_score\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Input, Dense, Bidirectional, LSTM, Lambda, Concatenate, Add, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# ---------------------------\n",
    "# 1. Set Seed for Reproducibility\n",
    "# ---------------------------\n",
    "def set_random_seed(seed=20):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    tf.config.experimental.enable_op_determinism()\n",
    "\n",
    "set_random_seed(20)\n",
    "\n",
    "# ---------------------------\n",
    "# 2. Load & Preprocess Data\n",
    "# ---------------------------\n",
    "# For demonstration, we use a basic univariate \"Close\" series.\n",
    "# Ensure that your DataFrame 'data' contains at least a \"Close\" column.\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# ---------------------------\n",
    "# 2. Load & Preprocess Data\n",
    "# ---------------------------\n",
    "# Separate features (X) and target (y)\n",
    "data.dropna(axis=0,inplace=True)\n",
    "y = data[['Close']].copy()\n",
    "X = data.drop('Close', axis=1).copy()\n",
    "\n",
    "# It's important to scale your features and target separately.\n",
    "# We'll need the 'scaler_y' later to inverse the transformation of our predictions.\n",
    "scaler_X = MinMaxScaler()\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "\n",
    "scaler_y = MinMaxScaler()\n",
    "y_scaled = scaler_y.fit_transform(y)\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# 3. Create 15-day Sequences for Multivariate Data\n",
    "# ---------------------------\n",
    "def create_multivariate_sequences(X_data, y_data, time_steps=15):\n",
    "    \"\"\"\n",
    "    Creates sequences for multivariate time series data.\n",
    "    \"\"\"\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X_data) - time_steps):\n",
    "        # Get a sequence of 'time_steps' from the features\n",
    "        Xs.append(X_data[i:(i + time_steps)])\n",
    "        # The target is the 'Close' price at the end of the sequence\n",
    "        ys.append(y_data[i + time_steps])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "\n",
    "# Create the sequences\n",
    "X_seq, y_seq = create_multivariate_sequences(X_scaled, y_scaled, time_steps=15)\n",
    "\n",
    "# Split the data into training, validation, and testing sets\n",
    "train_size = int(len(X_seq) * 0.7)\n",
    "val_size = int(len(X_seq) * 0.1)\n",
    "\n",
    "X_train, y_train = X_seq[:train_size], y_seq[:train_size]\n",
    "X_val, y_val = X_seq[train_size:train_size + val_size], y_seq[train_size:train_size + val_size]\n",
    "X_test, y_test = X_seq[train_size + val_size:], y_seq[train_size + val_size:]\n",
    "\n",
    "# The input for the model will have a shape of (number of samples, timesteps, number of features)\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "n_features = X.shape[1]\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T15:09:16.688886Z",
     "iopub.status.busy": "2025-07-02T15:09:16.688661Z",
     "iopub.status.idle": "2025-07-02T15:16:35.977162Z",
     "shell.execute_reply": "2025-07-02T15:16:35.976464Z",
     "shell.execute_reply.started": "2025-07-02T15:09:16.688870Z"
    },
    "id": "0Thi5iGcLUw3",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.layers import Multiply, Activation\n",
    "\n",
    "def build_Bilstm5_model(seq_length=15,n_features=n_features, scale_factor=0.2, recent_scale=0.1):\n",
    "    inputs = Input(shape=(seq_length, n_features))\n",
    "\n",
    "    # Full branch (15 days)\n",
    "    full_branch = Bidirectional(LSTM(128, return_sequences=False, dropout=0.2))(inputs)\n",
    "    full_branch = Dense(64, activation='relu')(full_branch)\n",
    "    long_term_return = Dense(1, activation='tanh')(full_branch)\n",
    "    long_term_return = Lambda(lambda x: x * scale_factor)(long_term_return)\n",
    "\n",
    "    # Recent branch (7 days)\n",
    "    recent_input = Lambda(lambda x: x[:, -7:, :])(inputs)\n",
    "    recent_branch = Bidirectional(LSTM(128, return_sequences=False, dropout=0.2))(recent_input)\n",
    "    recent_branch = Dense(64, activation='relu')(recent_branch)\n",
    "    mid_term_return = Dense(1, activation='tanh')(recent_branch)\n",
    "    mid_term_return = Lambda(lambda x: x * scale_factor)(mid_term_return)\n",
    "\n",
    "    # Very recent branch (1 day)\n",
    "    very_recent_input = Lambda(lambda x: x[:, -1:, :])(inputs)\n",
    "    very_recent_branch = Flatten()(very_recent_input)\n",
    "    very_recent_branch = Dense(32, activation='relu')(very_recent_branch)\n",
    "    short_term_return = Dense(1, activation='tanh')(very_recent_branch)\n",
    "    short_term_return = Lambda(lambda x: x * recent_scale)(short_term_return)\n",
    "\n",
    "    # Gating mechanisms\n",
    "    gate_7 = Dense(1, activation='sigmoid')(mid_term_return)\n",
    "    gate_1 = Dense(1, activation='sigmoid')(short_term_return)\n",
    "    gated_mid_term_return = Multiply()([mid_term_return, gate_7])\n",
    "    gated_short_term_return = Multiply()([short_term_return, gate_1])\n",
    "\n",
    "    # Fuse all branches\n",
    "    fused_returns = Add()([long_term_return, gated_mid_term_return, gated_short_term_return])\n",
    "    fused_returns = Dense(32, activation='relu')(fused_returns)\n",
    "    final_return = Dense(1, activation='tanh')(fused_returns)\n",
    "    final_return = Lambda(lambda x: x * scale_factor)(final_return)\n",
    "\n",
    "    last_day = Lambda(lambda x: tf.expand_dims(x[:, -1, 0], axis=-1))(inputs)\n",
    "    final_output = Lambda(lambda inputs: inputs[0] * (1 + inputs[1]))([last_day, final_return])\n",
    "\n",
    "    model = Model(inputs, final_output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "    return model\n",
    "\n",
    "# *Build the Modified Model with Gating*\n",
    "# model_gated = build_gated_multi_scale_model(seq_length=15, scale_factor=0.2, recent_scale=0.1)\n",
    "# model_gated.summary()\n",
    "\n",
    "# *Build the Modified Model with Attention-Based Residuals*\n",
    "model_attention = build_Bilstm5_model(seq_length=15, scale_factor=0.2, recent_scale=0.1)\n",
    "model_attention.summary()\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", patience=15, restore_best_weights=True, verbose=1)\n",
    "history = model_attention.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val), batch_size=8, callbacks=[early_stop], verbose=1)\n",
    "\n",
    "# ---------------------------\n",
    "# 7. Evaluate the Model\n",
    "# ---------------------------\n",
    "y_pred = model_attention.predict(X_test)\n",
    "# Predictions on test set\n",
    "##y_pred = model.predict(X_test)\n",
    "\n",
    "# Inverse transform predictions and actual values\n",
    "y_pred_inv = scaler_y.inverse_transform(y_pred)\n",
    "y_test_inv = scaler_y.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Inverse transform predictions and actual values\n",
    "y_pred_inv = scaler_y.inverse_transform(y_pred)\n",
    "y_test_inv = scaler_y.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Calculate Metrics\n",
    "r2 = r2_score(y_test_inv, y_pred_inv)\n",
    "mae = mean_absolute_error(y_test_inv, y_pred_inv)\n",
    "mse = mean_squared_error(y_test_inv, y_pred_inv)\n",
    "rmse = np.sqrt(mse)  # Root Mean Squared Error\n",
    "\n",
    "# Calculate the actual range of the test set\n",
    "actual_range = np.max(y_test_inv) - np.min(y_test_inv)\n",
    "\n",
    "# Compute Scaled Metrics\n",
    "mae_scaled = mae / actual_range\n",
    "mse_scaled = mse / (actual_range ** 2)\n",
    "rmse_scaled = rmse / actual_range\n",
    "\n",
    "# Explained Variance Score\n",
    "evs = explained_variance_score(y_test_inv, y_pred_inv)\n",
    "\n",
    "# Print the results\n",
    "print(f\"ðŸ“Š Final Results -\")\n",
    "print(f\"  RÂ²: {r2:.4f}\")\n",
    "print(f\"  MAE: {mae:.4f}, MAE Scaled: {mae_scaled:.4f}\")\n",
    "print(f\"  MSE: {mse:.4f}, MSE Scaled: {mse_scaled:.4f}\")\n",
    "print(f\"  RMSE: {rmse:.4f}, RMSE Scaled: {rmse_scaled:.4f}\")\n",
    "print(f\"  MAPE: {mean_absolute_percentage_error(y_test_inv, y_pred_inv) * 100:.2f}%\")\n",
    "print(f\"  EVS: {evs:.4f}\")\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot the first 100 points for better visibility\n",
    "num_points = min(100, len(y_test_inv))\n",
    "\n",
    "plt.plot(y_test_inv[:num_points], label=\"Actual\", linestyle=\"-\", linewidth=2, marker=\"o\", markersize=3, alpha=0.8)\n",
    "plt.plot(y_pred_inv[:num_points], label=\"Predicted\", linestyle=\"--\", linewidth=2, marker=\"x\", markersize=3, alpha=0.8)\n",
    "\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Stock Price\")\n",
    "plt.title(\"Actual vs Predicted Stock Prices (Zoomed In)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_8lddAHeLUxE"
   },
   "source": [
    "## OUR RANGE:SP500 (15-3-2008 to 15-3-2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RaLf9ZzWLUxE"
   },
   "source": [
    "- with single lstm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8QelxPJ-LUxE"
   },
   "source": [
    "- - without vix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T15:16:35.978388Z",
     "iopub.status.busy": "2025-07-02T15:16:35.978096Z",
     "iopub.status.idle": "2025-07-02T15:16:36.011405Z",
     "shell.execute_reply": "2025-07-02T15:16:36.010730Z",
     "shell.execute_reply.started": "2025-07-02T15:16:35.978364Z"
    },
    "id": "jd3rnLB2LUxF",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(\"/kaggle/input/sp500-data/SP500 Vix (1).csv\")\n",
    "\n",
    "# Ensure the required columns exist\n",
    "if \"Price\" in df.columns and \"Open\" in df.columns:\n",
    "    # Calculate the percentage change\n",
    "    df[\"Change %\"] = ((df[\"Price\"] - df[\"Open\"]) / df[\"Price\"]) * 100\n",
    "\n",
    "    # Save the updated CSV file\n",
    "    # df.to_csv(\"SP 500 (2).csv\", index=False)\n",
    "\n",
    "    # Display first few rows\n",
    "    print(df.head())\n",
    "else:\n",
    "    print(\"Error: CSV file must contain 'Price' and 'Open' columns.\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T15:16:36.013150Z",
     "iopub.status.busy": "2025-07-02T15:16:36.012754Z",
     "iopub.status.idle": "2025-07-02T15:16:36.031819Z",
     "shell.execute_reply": "2025-07-02T15:16:36.031080Z",
     "shell.execute_reply.started": "2025-07-02T15:16:36.013134Z"
    },
    "id": "KpLmSdycLUxF",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "vix = df\n",
    "vix.drop(\"Vol.\",axis=1,inplace=True)\n",
    "def convert_volume(val):\n",
    "    if pd.isna(val) or val == '-':  # Handle NaN or '-' cases\n",
    "        return np.nan\n",
    "    val = val.strip().replace(',', '')  # Remove spaces & commas\n",
    "    if val[-1] == 'K': return float(val[:-1]) * 1e3\n",
    "    if val[-1] == 'M': return float(val[:-1]) * 1e6\n",
    "    if val[-1] == 'B': return float(val[:-1]) * 1e9\n",
    "    return float(val)\n",
    "\n",
    "#vix[\"Vol.\"] = vix[\"Vol.\"].apply(convert_volume)\n",
    "vix.rename(columns={'Open':'Vopen','High':'Vhigh','Low':'Vlow','Change %':'Vchange%'}, inplace=True)\n",
    "vix[\"Vchange%\"] = vix[\"Vchange%\"].astype(str).str.replace(\"%\", \"\").astype(float)\n",
    "vix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T15:16:36.032937Z",
     "iopub.status.busy": "2025-07-02T15:16:36.032670Z",
     "iopub.status.idle": "2025-07-02T15:16:36.062563Z",
     "shell.execute_reply": "2025-07-02T15:16:36.062070Z",
     "shell.execute_reply.started": "2025-07-02T15:16:36.032897Z"
    },
    "id": "QAo-OdoTLUxF",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(\"/kaggle/input/sp500-data/sp500_historical_data (2).csv\")\n",
    "\n",
    "# Ensure the required columns exist\n",
    "if \"Price\" in df.columns and \"Open\" in df.columns:\n",
    "    # Calculate the percentage change\n",
    "    df[\"Change %\"] = ((df[\"Price\"] - df[\"Open\"]) / df[\"Price\"]) * 100\n",
    "\n",
    "    # Save the updated CSV file\n",
    "    # df.to_csv(\"SP 500 (2).csv\", index=False)\n",
    "\n",
    "    # Display first few rows\n",
    "    print(df.head())\n",
    "else:\n",
    "    print(\"Error: CSV file must contain 'Price' and 'Open' columns.\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T15:16:36.063366Z",
     "iopub.status.busy": "2025-07-02T15:16:36.063175Z",
     "iopub.status.idle": "2025-07-02T15:16:36.108358Z",
     "shell.execute_reply": "2025-07-02T15:16:36.107703Z",
     "shell.execute_reply.started": "2025-07-02T15:16:36.063345Z"
    },
    "id": "8t5YryNJLUxG",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data=df\n",
    "data=data[::-1]\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "print(data.head())\n",
    "data.nunique()\n",
    "\n",
    "data.sort_index(axis=1,ascending=True)\n",
    "data.rename(columns={'Price': 'Close'}, inplace=True)\n",
    "df = data.copy()  # Ensure we don't modify the original dataset\n",
    "\n",
    "# Convert financial columns to numeric (remove commas)\n",
    "for col in [\"Close\", \"Open\", \"High\", \"Low\"]:\n",
    "    df[col] = df[col].astype(str).str.replace(\",\", \"\").astype(float)\n",
    "\n",
    "# Function to convert 'Vol.' column\n",
    "#df.drop(\"Vol.\",axis=1,inplace=True)\n",
    "\n",
    "# Convert 'Change %' column (remove '%' and convert to float)\n",
    "df[\"Change %\"] = df[\"Change %\"].astype(str).str.replace(\"%\", \"\").astype(float)\n",
    "\n",
    "# Print final DataFrame\n",
    "print(df.dtypes)\n",
    "print(df)\n",
    "\n",
    "# Assign back to 'data' (if needed)\n",
    "data = df\n",
    "#data['Date'] = pd.to_datetime(data['Date'], format=\"%d-%m-%Y\")\n",
    "\n",
    "# For 'vix', the date format is \"MM/DD/YYYY\"\n",
    "#vix['Date'] = pd.to_datetime(vix['Date'], format=\"%m/%d/%Y\")\n",
    "#data = pd.merge(data, vix, on='Date', how='inner')\n",
    "#row=data[data[\"Vol.\"].isna()]\n",
    "data.drop(['Date'], axis=1, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T15:16:36.109131Z",
     "iopub.status.busy": "2025-07-02T15:16:36.108972Z",
     "iopub.status.idle": "2025-07-02T15:16:36.131592Z",
     "shell.execute_reply": "2025-07-02T15:16:36.131018Z",
     "shell.execute_reply.started": "2025-07-02T15:16:36.109118Z"
    },
    "id": "zOa9rlgzLUxG",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, mean_absolute_percentage_error, explained_variance_score\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Input, Dense, Bidirectional, LSTM, Lambda, Concatenate, Add, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# 2. Load & Preprocess Data\n",
    "# ---------------------------\n",
    "# For demonstration, we use a basic univariate \"Close\" series.\n",
    "# Ensure that your DataFrame 'data' contains at least a \"Close\" column.\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# ---------------------------\n",
    "# 2. Load & Preprocess Data\n",
    "# ---------------------------\n",
    "# Separate features (X) and target (y)\n",
    "y = data[['Close']].copy()\n",
    "X = data.drop('Close', axis=1).copy()\n",
    "\n",
    "# It's important to scale your features and target separately.\n",
    "# We'll need the 'scaler_y' later to inverse the transformation of our predictions.\n",
    "scaler_X = MinMaxScaler()\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "\n",
    "scaler_y = MinMaxScaler()\n",
    "y_scaled = scaler_y.fit_transform(y)\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# 3. Create 15-day Sequences for Multivariate Data\n",
    "# ---------------------------\n",
    "def create_multivariate_sequences(X_data, y_data, time_steps=15):\n",
    "    \"\"\"\n",
    "    Creates sequences for multivariate time series data.\n",
    "    \"\"\"\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X_data) - time_steps):\n",
    "        # Get a sequence of 'time_steps' from the features\n",
    "        Xs.append(X_data[i:(i + time_steps)])\n",
    "        # The target is the 'Close' price at the end of the sequence\n",
    "        ys.append(y_data[i + time_steps])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "\n",
    "# Create the sequences\n",
    "X_seq, y_seq = create_multivariate_sequences(X_scaled, y_scaled, time_steps=15)\n",
    "\n",
    "# Split the data into training, validation, and testing sets\n",
    "train_size = int(len(X_seq) * 0.7)\n",
    "val_size = int(len(X_seq) * 0.1)\n",
    "\n",
    "X_train, y_train = X_seq[:train_size], y_seq[:train_size]\n",
    "X_val, y_val = X_seq[train_size:train_size + val_size], y_seq[train_size:train_size + val_size]\n",
    "X_test, y_test = X_seq[train_size + val_size:], y_seq[train_size + val_size:]\n",
    "\n",
    "# The input for the model will have a shape of (number of samples, timesteps, number of features)\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "n_features = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T15:16:36.132428Z",
     "iopub.status.busy": "2025-07-02T15:16:36.132202Z",
     "iopub.status.idle": "2025-07-02T15:17:15.703803Z",
     "shell.execute_reply": "2025-07-02T15:17:15.703126Z",
     "shell.execute_reply.started": "2025-07-02T15:16:36.132407Z"
    },
    "id": "Km_sWDbhLUxG",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.layers import Multiply, Activation\n",
    "\n",
    "def build_lstm_model(seq_length=15,n_features=n_features, scale_factor=0.2, recent_scale=0.1):\n",
    "    inputs = Input(shape=(seq_length, n_features))\n",
    "    # Simple LSTM (unidirectional)\n",
    "    x = LSTM(128, return_sequences=False, dropout=0.2)(inputs)\n",
    "    x = Dense(16)(x)\n",
    "    x = Dense(1,activation=\"tanh\")(x)\n",
    "    x = Lambda(lambda x: x * scale_factor)(x)\n",
    "\n",
    "    # Use the last day's price for final output calculation\n",
    "    last_day = Lambda(lambda x: tf.expand_dims(x[:, -1, 0], axis=-1))(inputs)\n",
    "    final_output = Lambda(lambda inputs: inputs[0] * (1 + inputs[1]))([last_day, x])\n",
    "\n",
    "    model = Model(inputs, final_output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "    return model\n",
    "\n",
    "# *Build the Modified Model with Gating*\n",
    "# model_gated = build_gated_multi_scale_model(seq_length=15, scale_factor=0.2, recent_scale=0.1)\n",
    "# model_gated.summary()\n",
    "\n",
    "# *Build the Modified Model with Attention-Based Residuals*\n",
    "model_attention = build_lstm_model(seq_length=15, scale_factor=0.2, recent_scale=0.1)\n",
    "model_attention.summary()\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", patience=15, restore_best_weights=True, verbose=1)\n",
    "history = model_attention.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val), batch_size=8, callbacks=[early_stop], verbose=1)\n",
    "\n",
    "# ---------------------------\n",
    "# 7. Evaluate the Model\n",
    "# ---------------------------\n",
    "y_pred = model_attention.predict(X_test)\n",
    "# Predictions on test set\n",
    "##y_pred = model.predict(X_test)\n",
    "\n",
    "# Inverse transform predictions and actual values\n",
    "y_pred_inv = scaler_y.inverse_transform(y_pred)\n",
    "y_test_inv = scaler_y.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Inverse transform predictions and actual values\n",
    "y_pred_inv = scaler_y.inverse_transform(y_pred)\n",
    "y_test_inv = scaler_y.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Calculate Metrics\n",
    "r2 = r2_score(y_test_inv, y_pred_inv)\n",
    "mae = mean_absolute_error(y_test_inv, y_pred_inv)\n",
    "mse = mean_squared_error(y_test_inv, y_pred_inv)\n",
    "rmse = np.sqrt(mse)  # Root Mean Squared Error\n",
    "\n",
    "# Calculate the actual range of the test set\n",
    "actual_range = np.max(y_test_inv) - np.min(y_test_inv)\n",
    "\n",
    "# Compute Scaled Metrics\n",
    "mae_scaled = mae / actual_range\n",
    "mse_scaled = mse / (actual_range ** 2)\n",
    "rmse_scaled = rmse / actual_range\n",
    "\n",
    "# Explained Variance Score\n",
    "evs = explained_variance_score(y_test_inv, y_pred_inv)\n",
    "\n",
    "# Print the results\n",
    "print(f\"ðŸ“Š Final Results -\")\n",
    "print(f\"  RÂ²: {r2:.4f}\")\n",
    "print(f\"  MAE: {mae:.4f}, MAE Scaled: {mae_scaled:.4f}\")\n",
    "print(f\"  MSE: {mse:.4f}, MSE Scaled: {mse_scaled:.4f}\")\n",
    "print(f\"  RMSE: {rmse:.4f}, RMSE Scaled: {rmse_scaled:.4f}\")\n",
    "print(f\"  MAPE: {mean_absolute_percentage_error(y_test_inv, y_pred_inv) * 100:.2f}%\")\n",
    "print(f\"  EVS: {evs:.4f}\")\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot the first 100 points for better visibility\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "num_points = max(100, len(y_test_inv))\n",
    "\n",
    "# Actual: Royal Blue\n",
    "plt.plot(\n",
    "    y_test_inv[:num_points],\n",
    "    label=\"Actual\",\n",
    "    linestyle=\"-\",\n",
    "    linewidth=3.5,\n",
    "    color=\"#4169E1\"  # Royal Blue\n",
    ")\n",
    "\n",
    "# Predicted: Crimson Red\n",
    "plt.plot(\n",
    "    y_pred_inv[:num_points],\n",
    "    label=\"Predicted\",\n",
    "    linestyle=\"--\",\n",
    "    linewidth=3.5,\n",
    "    color=\"#DC143C\"  # Crimson Red\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Time\", fontsize=14, fontweight=\"bold\")\n",
    "plt.ylabel(\"Stock Price\", fontsize=14, fontweight=\"bold\")\n",
    "plt.title(\"Actual vs Predicted Stock Prices\", fontsize=16, fontweight=\"bold\")\n",
    "\n",
    "plt.legend(fontsize=12, loc=\"upper left\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T15:17:15.706708Z",
     "iopub.status.busy": "2025-07-02T15:17:15.706503Z",
     "iopub.status.idle": "2025-07-02T15:18:42.794566Z",
     "shell.execute_reply": "2025-07-02T15:18:42.793888Z",
     "shell.execute_reply.started": "2025-07-02T15:17:15.706693Z"
    },
    "id": "W-4GFROULUxH",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Multiply, Activation\n",
    "\n",
    "def build_Bilstm1_model(seq_length=15,n_features=n_features, scale_factor=0.2, recent_scale=0.1):\n",
    "    inputs = Input(shape=(seq_length, n_features))\n",
    "    # 15-day full branch with BiLSTM\n",
    "    x = Bidirectional(LSTM(128, return_sequences=False, dropout=0.2))(inputs)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dense(1, activation='tanh')(x)\n",
    "    x = Lambda(lambda x: x * scale_factor)(x)\n",
    "\n",
    "    last_day = Lambda(lambda x: tf.expand_dims(x[:, -1, 0], axis=-1))(inputs)\n",
    "    final_output = Lambda(lambda inputs: inputs[0] * (1 + inputs[1]))([last_day, x])\n",
    "\n",
    "    model = Model(inputs, final_output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "    return model\n",
    "\n",
    "# *Build the Modified Model with Gating*\n",
    "# model_gated = build_gated_multi_scale_model(seq_length=15, scale_factor=0.2, recent_scale=0.1)\n",
    "# model_gated.summary()\n",
    "\n",
    "# *Build the Modified Model with Attention-Based Residuals*\n",
    "model_attention = build_Bilstm1_model(seq_length=15, scale_factor=0.2, recent_scale=0.1)\n",
    "model_attention.summary()\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", patience=15, restore_best_weights=True, verbose=1)\n",
    "history = model_attention.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val), batch_size=8, callbacks=[early_stop], verbose=1)\n",
    "\n",
    "# ---------------------------\n",
    "# 7. Evaluate the Model\n",
    "# ---------------------------\n",
    "y_pred = model_attention.predict(X_test)\n",
    "# Predictions on test set\n",
    "##y_pred = model.predict(X_test)\n",
    "\n",
    "# Inverse transform predictions and actual values\n",
    "y_pred_inv = scaler_y.inverse_transform(y_pred)\n",
    "y_test_inv = scaler_y.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Inverse transform predictions and actual values\n",
    "y_pred_inv = scaler_y.inverse_transform(y_pred)\n",
    "y_test_inv = scaler_y.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Calculate Metrics\n",
    "r2 = r2_score(y_test_inv, y_pred_inv)\n",
    "mae = mean_absolute_error(y_test_inv, y_pred_inv)\n",
    "mse = mean_squared_error(y_test_inv, y_pred_inv)\n",
    "rmse = np.sqrt(mse)  # Root Mean Squared Error\n",
    "\n",
    "# Calculate the actual range of the test set\n",
    "actual_range = np.max(y_test_inv) - np.min(y_test_inv)\n",
    "\n",
    "# Compute Scaled Metrics\n",
    "mae_scaled = mae / actual_range\n",
    "mse_scaled = mse / (actual_range ** 2)\n",
    "rmse_scaled = rmse / actual_range\n",
    "\n",
    "# Explained Variance Score\n",
    "evs = explained_variance_score(y_test_inv, y_pred_inv)\n",
    "\n",
    "# Print the results\n",
    "print(f\"ðŸ“Š Final Results -\")\n",
    "print(f\"  RÂ²: {r2:.4f}\")\n",
    "print(f\"  MAE: {mae:.4f}, MAE Scaled: {mae_scaled:.4f}\")\n",
    "print(f\"  MSE: {mse:.4f}, MSE Scaled: {mse_scaled:.4f}\")\n",
    "print(f\"  RMSE: {rmse:.4f}, RMSE Scaled: {rmse_scaled:.4f}\")\n",
    "print(f\"  MAPE: {mean_absolute_percentage_error(y_test_inv, y_pred_inv) * 100:.2f}%\")\n",
    "print(f\"  EVS: {evs:.4f}\")\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot the first 100 points for better visibility\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "num_points = max(100, len(y_test_inv))\n",
    "\n",
    "plt.plot(y_test_inv[:num_points], label=\"Actual\", linestyle=\"-\", linewidth=2, marker=\"o\", markersize=3, alpha=0.8, color=\"#1f77b4\")\n",
    "plt.plot(y_pred_inv[:num_points], label=\"Predicted\", linestyle=\"--\", linewidth=2, marker=\"x\", markersize=3, alpha=0.8, color=\"#ff7f0e\")\n",
    "\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Stock Price\")\n",
    "plt.title(\"Actual vs Predicted Stock Prices (Zoomed In)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "num_points = max(100, len(y_test_inv))\n",
    "\n",
    "# Actual: Royal Blue\n",
    "plt.plot(\n",
    "    y_test_inv[:num_points],\n",
    "    label=\"Actual\",\n",
    "    linestyle=\"-\",\n",
    "    linewidth=3.5,\n",
    "    color=\"#4169E1\"  # Royal Blue\n",
    ")\n",
    "\n",
    "# Predicted: Crimson Red\n",
    "plt.plot(\n",
    "    y_pred_inv[:num_points],\n",
    "    label=\"Predicted\",\n",
    "    linestyle=\"--\",\n",
    "    linewidth=3.5,\n",
    "    color=\"#DC143C\"  # Crimson Red\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Time\", fontsize=14, fontweight=\"bold\")\n",
    "plt.ylabel(\"Stock Price\", fontsize=14, fontweight=\"bold\")\n",
    "plt.title(\"Actual vs Predicted Stock Prices\", fontsize=16, fontweight=\"bold\")\n",
    "\n",
    "plt.legend(fontsize=12, loc=\"upper left\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T15:18:42.795568Z",
     "iopub.status.busy": "2025-07-02T15:18:42.795333Z",
     "iopub.status.idle": "2025-07-02T15:21:52.517775Z",
     "shell.execute_reply": "2025-07-02T15:21:52.517103Z",
     "shell.execute_reply.started": "2025-07-02T15:18:42.795543Z"
    },
    "id": "CUxt1ikeLUxH",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.layers import Multiply, Activation\n",
    "\n",
    "def build_Bilstm2_model(seq_length=15,n_features=n_features, scale_factor=0.2, recent_scale=0.1):\n",
    "    inputs = Input(shape=(seq_length, n_features))\n",
    "\n",
    "    # Full branch (15 days)\n",
    "    full_branch = Bidirectional(LSTM(128, return_sequences=False, dropout=0.2))(inputs)\n",
    "    full_branch = Dense(64, activation='relu')(full_branch)\n",
    "    long_term_return = Dense(1, activation='tanh')(full_branch)\n",
    "    long_term_return = Lambda(lambda x: x * scale_factor)(long_term_return)\n",
    "\n",
    "    # Recent branch (last 7 days)\n",
    "    recent_input = Lambda(lambda x: x[:, -7:, :])(inputs)\n",
    "    recent_branch = Bidirectional(LSTM(128, return_sequences=False, dropout=0.2))(recent_input)\n",
    "    recent_branch = Dense(64, activation='relu')(recent_branch)\n",
    "    mid_term_return = Dense(1, activation='tanh')(recent_branch)\n",
    "    mid_term_return = Lambda(lambda x: x * scale_factor)(mid_term_return)\n",
    "\n",
    "    # Gate the 7-day branch output\n",
    "    gate_7 = Dense(1, activation='sigmoid')(mid_term_return)\n",
    "    gated_mid_term_return = Multiply()([mid_term_return, gate_7])\n",
    "\n",
    "    # Fuse the two branches\n",
    "    fused_returns = Add()([long_term_return, gated_mid_term_return])\n",
    "    fused_returns = Dense(32, activation='relu')(fused_returns)\n",
    "    final_return = Dense(1, activation='tanh')(fused_returns)\n",
    "    final_return = Lambda(lambda x: x * scale_factor)(final_return)\n",
    "\n",
    "    last_day = Lambda(lambda x: tf.expand_dims(x[:, -1, 0], axis=-1))(inputs)\n",
    "    final_output = Lambda(lambda inputs: inputs[0] * (1 + inputs[1]))([last_day, final_return])\n",
    "\n",
    "    model = Model(inputs, final_output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "    return model\n",
    "\n",
    "# *Build the Modified Model with Gating*\n",
    "# model_gated = build_gated_multi_scale_model(seq_length=15, scale_factor=0.2, recent_scale=0.1)\n",
    "# model_gated.summary()\n",
    "\n",
    "# *Build the Modified Model with Attention-Based Residuals*\n",
    "model_attention = build_Bilstm2_model(seq_length=15, scale_factor=0.2, recent_scale=0.1)\n",
    "model_attention.summary()\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", patience=15, restore_best_weights=True, verbose=1)\n",
    "history = model_attention.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val), batch_size=8, callbacks=[early_stop], verbose=1)\n",
    "\n",
    "# ---------------------------\n",
    "# 7. Evaluate the Model\n",
    "# ---------------------------\n",
    "y_pred = model_attention.predict(X_test)\n",
    "# Predictions on test set\n",
    "##y_pred = model.predict(X_test)\n",
    "\n",
    "# Inverse transform predictions and actual values\n",
    "y_pred_inv = scaler_y.inverse_transform(y_pred)\n",
    "y_test_inv = scaler_y.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Inverse transform predictions and actual values\n",
    "y_pred_inv = scaler_y.inverse_transform(y_pred)\n",
    "y_test_inv = scaler_y.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Calculate Metrics\n",
    "r2 = r2_score(y_test_inv, y_pred_inv)\n",
    "mae = mean_absolute_error(y_test_inv, y_pred_inv)\n",
    "mse = mean_squared_error(y_test_inv, y_pred_inv)\n",
    "rmse = np.sqrt(mse)  # Root Mean Squared Error\n",
    "\n",
    "# Calculate the actual range of the test set\n",
    "actual_range = np.max(y_test_inv) - np.min(y_test_inv)\n",
    "\n",
    "# Compute Scaled Metrics\n",
    "mae_scaled = mae / actual_range\n",
    "mse_scaled = mse / (actual_range ** 2)\n",
    "rmse_scaled = rmse / actual_range\n",
    "\n",
    "# Explained Variance Score\n",
    "evs = explained_variance_score(y_test_inv, y_pred_inv)\n",
    "\n",
    "# Print the results\n",
    "print(f\"ðŸ“Š Final Results -\")\n",
    "print(f\"  RÂ²: {r2:.4f}\")\n",
    "print(f\"  MAE: {mae:.4f}, MAE Scaled: {mae_scaled:.4f}\")\n",
    "print(f\"  MSE: {mse:.4f}, MSE Scaled: {mse_scaled:.4f}\")\n",
    "print(f\"  RMSE: {rmse:.4f}, RMSE Scaled: {rmse_scaled:.4f}\")\n",
    "print(f\"  MAPE: {mean_absolute_percentage_error(y_test_inv, y_pred_inv) * 100:.2f}%\")\n",
    "print(f\"  EVS: {evs:.4f}\")\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot the first 100 points for better visibility\n",
    "num_points = min(100, len(y_test_inv))\n",
    "\n",
    "plt.plot(y_test_inv[:num_points], label=\"Actual\", linestyle=\"-\", linewidth=2, marker=\"o\", markersize=3, alpha=0.8)\n",
    "plt.plot(y_pred_inv[:num_points], label=\"Predicted\", linestyle=\"--\", linewidth=2, marker=\"x\", markersize=3, alpha=0.8)\n",
    "\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Stock Price\")\n",
    "plt.title(\"Actual vs Predicted Stock Prices (Zoomed In)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T15:21:52.518873Z",
     "iopub.status.busy": "2025-07-02T15:21:52.518653Z",
     "iopub.status.idle": "2025-07-02T15:23:51.488557Z",
     "shell.execute_reply": "2025-07-02T15:23:51.487938Z",
     "shell.execute_reply.started": "2025-07-02T15:21:52.518858Z"
    },
    "id": "oXcqZXUGLUxI",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.layers import Multiply, Activation\n",
    "\n",
    "def build_Bilstm3_model(seq_length=15,n_features=n_features, scale_factor=0.2, recent_scale=0.1):\n",
    "    inputs = Input(shape=(seq_length, n_features))\n",
    "\n",
    "    # Recent branch (last 7 days)\n",
    "    recent_input = Lambda(lambda x: x[:, -7:, :])(inputs)\n",
    "    recent_branch = Bidirectional(LSTM(128, return_sequences=False, dropout=0.2))(recent_input)\n",
    "    recent_branch = Dense(64, activation='relu')(recent_branch)\n",
    "    mid_term_return = Dense(1, activation='tanh')(recent_branch)\n",
    "    mid_term_return = Lambda(lambda x: x * scale_factor)(mid_term_return)\n",
    "\n",
    "    # Very recent branch (last 1 day)\n",
    "    very_recent_input = Lambda(lambda x: x[:, -1:, :])(inputs)\n",
    "    very_recent_branch = Flatten()(very_recent_input)\n",
    "    very_recent_branch = Dense(32, activation='relu')(very_recent_branch)\n",
    "    short_term_return = Dense(1, activation='tanh')(very_recent_branch)\n",
    "    short_term_return = Lambda(lambda x: x * recent_scale)(short_term_return)\n",
    "\n",
    "    # Gating mechanisms\n",
    "    gate_7 = Dense(1, activation='sigmoid')(mid_term_return)\n",
    "    gate_1 = Dense(1, activation='sigmoid')(short_term_return)\n",
    "    gated_mid_term_return = Multiply()([mid_term_return, gate_7])\n",
    "    gated_short_term_return = Multiply()([short_term_return, gate_1])\n",
    "\n",
    "    # Combine gated outputs\n",
    "    fused_returns = Add()([gated_mid_term_return, gated_short_term_return])\n",
    "    fused_returns = Dense(32, activation='relu')(fused_returns)\n",
    "    final_return = Dense(1, activation='tanh')(fused_returns)\n",
    "    final_return = Lambda(lambda x: x * scale_factor)(final_return)\n",
    "\n",
    "    last_day = Lambda(lambda x: tf.expand_dims(x[:, -1, 0], axis=-1))(inputs)\n",
    "    final_output = Lambda(lambda inputs: inputs[0] * (1 + inputs[1]))([last_day, final_return])\n",
    "\n",
    "    model = Model(inputs, final_output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "    return model\n",
    "\n",
    "# *Build the Modified Model with Gating*\n",
    "# model_gated = build_gated_multi_scale_model(seq_length=15, scale_factor=0.2, recent_scale=0.1)\n",
    "# model_gated.summary()\n",
    "\n",
    "# *Build the Modified Model with Attention-Based Residuals*\n",
    "model_attention = build_Bilstm3_model(seq_length=15, scale_factor=0.2, recent_scale=0.1)\n",
    "model_attention.summary()\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", patience=15, restore_best_weights=True, verbose=1)\n",
    "history = model_attention.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val), batch_size=8, callbacks=[early_stop], verbose=1)\n",
    "\n",
    "# ---------------------------\n",
    "# 7. Evaluate the Model\n",
    "# ---------------------------\n",
    "y_pred = model_attention.predict(X_test)\n",
    "# Predictions on test set\n",
    "##y_pred = model.predict(X_test)\n",
    "\n",
    "# Inverse transform predictions and actual values\n",
    "y_pred_inv = scaler_y.inverse_transform(y_pred)\n",
    "y_test_inv = scaler_y.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Inverse transform predictions and actual values\n",
    "y_pred_inv = scaler_y.inverse_transform(y_pred)\n",
    "y_test_inv = scaler_y.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Calculate Metrics\n",
    "r2 = r2_score(y_test_inv, y_pred_inv)\n",
    "mae = mean_absolute_error(y_test_inv, y_pred_inv)\n",
    "mse = mean_squared_error(y_test_inv, y_pred_inv)\n",
    "rmse = np.sqrt(mse)  # Root Mean Squared Error\n",
    "\n",
    "# Calculate the actual range of the test set\n",
    "actual_range = np.max(y_test_inv) - np.min(y_test_inv)\n",
    "\n",
    "# Compute Scaled Metrics\n",
    "mae_scaled = mae / actual_range\n",
    "mse_scaled = mse / (actual_range ** 2)\n",
    "rmse_scaled = rmse / actual_range\n",
    "\n",
    "# Explained Variance Score\n",
    "evs = explained_variance_score(y_test_inv, y_pred_inv)\n",
    "\n",
    "# Print the results\n",
    "print(f\"ðŸ“Š Final Results -\")\n",
    "print(f\"  RÂ²: {r2:.4f}\")\n",
    "print(f\"  MAE: {mae:.4f}, MAE Scaled: {mae_scaled:.4f}\")\n",
    "print(f\"  MSE: {mse:.4f}, MSE Scaled: {mse_scaled:.4f}\")\n",
    "print(f\"  RMSE: {rmse:.4f}, RMSE Scaled: {rmse_scaled:.4f}\")\n",
    "print(f\"  MAPE: {mean_absolute_percentage_error(y_test_inv, y_pred_inv) * 100:.2f}%\")\n",
    "print(f\"  EVS: {evs:.4f}\")\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot the first 100 points for better visibility\n",
    "num_points = min(100, len(y_test_inv))\n",
    "\n",
    "plt.plot(y_test_inv[:num_points], label=\"Actual\", linestyle=\"-\", linewidth=2, marker=\"o\", markersize=3, alpha=0.8)\n",
    "plt.plot(y_pred_inv[:num_points], label=\"Predicted\", linestyle=\"--\", linewidth=2, marker=\"x\", markersize=3, alpha=0.8)\n",
    "\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Stock Price\")\n",
    "plt.title(\"Actual vs Predicted Stock Prices (Zoomed In)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T15:23:51.489600Z",
     "iopub.status.busy": "2025-07-02T15:23:51.489407Z",
     "iopub.status.idle": "2025-07-02T15:28:09.033011Z",
     "shell.execute_reply": "2025-07-02T15:28:09.032353Z",
     "shell.execute_reply.started": "2025-07-02T15:23:51.489579Z"
    },
    "id": "RYpXnSEYLUxI",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.layers import Multiply, Activation\n",
    "\n",
    "def build_Bilstm5_model(seq_length=15,n_features=n_features, scale_factor=0.2, recent_scale=0.1):\n",
    "    inputs = Input(shape=(seq_length, n_features))\n",
    "\n",
    "    # Full branch (15 days)\n",
    "    full_branch = Bidirectional(LSTM(128, return_sequences=False, dropout=0.2))(inputs)\n",
    "    full_branch = Dense(64, activation='relu')(full_branch)\n",
    "    long_term_return = Dense(1, activation='tanh')(full_branch)\n",
    "    long_term_return = Lambda(lambda x: x * scale_factor)(long_term_return)\n",
    "\n",
    "    # Recent branch (7 days)\n",
    "    recent_input = Lambda(lambda x: x[:, -7:, :])(inputs)\n",
    "    recent_branch = Bidirectional(LSTM(128, return_sequences=False, dropout=0.2))(recent_input)\n",
    "    recent_branch = Dense(64, activation='relu')(recent_branch)\n",
    "    mid_term_return = Dense(1, activation='tanh')(recent_branch)\n",
    "    mid_term_return = Lambda(lambda x: x * scale_factor)(mid_term_return)\n",
    "\n",
    "    # Very recent branch (1 day)\n",
    "    very_recent_input = Lambda(lambda x: x[:, -1:, :])(inputs)\n",
    "    very_recent_branch = Flatten()(very_recent_input)\n",
    "    very_recent_branch = Dense(32, activation='relu')(very_recent_branch)\n",
    "    short_term_return = Dense(1, activation='tanh')(very_recent_branch)\n",
    "    short_term_return = Lambda(lambda x: x * recent_scale)(short_term_return)\n",
    "\n",
    "    # Gating mechanisms\n",
    "    gate_7 = Dense(1, activation='sigmoid')(mid_term_return)\n",
    "    gate_1 = Dense(1, activation='sigmoid')(short_term_return)\n",
    "    gated_mid_term_return = Multiply()([mid_term_return, gate_7])\n",
    "    gated_short_term_return = Multiply()([short_term_return, gate_1])\n",
    "\n",
    "    # Fuse all branches\n",
    "    fused_returns = Add()([long_term_return, gated_mid_term_return, gated_short_term_return])\n",
    "    fused_returns = Dense(32, activation='relu')(fused_returns)\n",
    "    final_return = Dense(1, activation='tanh')(fused_returns)\n",
    "    final_return = Lambda(lambda x: x * scale_factor)(final_return)\n",
    "\n",
    "    last_day = Lambda(lambda x: tf.expand_dims(x[:, -1, 0], axis=-1))(inputs)\n",
    "    final_output = Lambda(lambda inputs: inputs[0] * (1 + inputs[1]))([last_day, final_return])\n",
    "\n",
    "    model = Model(inputs, final_output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "    return model\n",
    "\n",
    "# *Build the Modified Model with Gating*\n",
    "# model_gated = build_gated_multi_scale_model(seq_length=15, scale_factor=0.2, recent_scale=0.1)\n",
    "# model_gated.summary()\n",
    "\n",
    "# *Build the Modified Model with Attention-Based Residuals*\n",
    "model_attention = build_Bilstm5_model(seq_length=15, scale_factor=0.2, recent_scale=0.1)\n",
    "model_attention.summary()\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", patience=15, restore_best_weights=True, verbose=1)\n",
    "history = model_attention.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val), batch_size=8, callbacks=[early_stop], verbose=1)\n",
    "\n",
    "# ---------------------------\n",
    "# 7. Evaluate the Model\n",
    "# ---------------------------\n",
    "y_pred = model_attention.predict(X_test)\n",
    "# Predictions on test set\n",
    "##y_pred = model.predict(X_test)\n",
    "\n",
    "# Inverse transform predictions and actual values\n",
    "y_pred_inv = scaler_y.inverse_transform(y_pred)\n",
    "y_test_inv = scaler_y.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Inverse transform predictions and actual values\n",
    "y_pred_inv = scaler_y.inverse_transform(y_pred)\n",
    "y_test_inv = scaler_y.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Calculate Metrics\n",
    "r2 = r2_score(y_test_inv, y_pred_inv)\n",
    "mae = mean_absolute_error(y_test_inv, y_pred_inv)\n",
    "mse = mean_squared_error(y_test_inv, y_pred_inv)\n",
    "rmse = np.sqrt(mse)  # Root Mean Squared Error\n",
    "\n",
    "# Calculate the actual range of the test set\n",
    "actual_range = np.max(y_test_inv) - np.min(y_test_inv)\n",
    "\n",
    "# Compute Scaled Metrics\n",
    "mae_scaled = mae / actual_range\n",
    "mse_scaled = mse / (actual_range ** 2)\n",
    "rmse_scaled = rmse / actual_range\n",
    "\n",
    "# Explained Variance Score\n",
    "evs = explained_variance_score(y_test_inv, y_pred_inv)\n",
    "\n",
    "# Print the results\n",
    "print(f\"ðŸ“Š Final Results -\")\n",
    "print(f\"  RÂ²: {r2:.4f}\")\n",
    "print(f\"  MAE: {mae:.4f}, MAE Scaled: {mae_scaled:.4f}\")\n",
    "print(f\"  MSE: {mse:.4f}, MSE Scaled: {mse_scaled:.4f}\")\n",
    "print(f\"  RMSE: {rmse:.4f}, RMSE Scaled: {rmse_scaled:.4f}\")\n",
    "print(f\"  MAPE: {mean_absolute_percentage_error(y_test_inv, y_pred_inv) * 100:.2f}%\")\n",
    "print(f\"  EVS: {evs:.4f}\")\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot the first 100 points for better visibility\n",
    "num_points = min(100, len(y_test_inv))\n",
    "\n",
    "plt.plot(y_test_inv[:num_points], label=\"Actual\", linestyle=\"-\", linewidth=2, marker=\"o\", markersize=3, alpha=0.8)\n",
    "plt.plot(y_pred_inv[:num_points], label=\"Predicted\", linestyle=\"--\", linewidth=2, marker=\"x\", markersize=3, alpha=0.8)\n",
    "\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Stock Price\")\n",
    "plt.title(\"Actual vs Predicted Stock Prices (Zoomed In)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5D_xnZukLUxJ"
   },
   "source": [
    "- with vix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T15:28:09.033829Z",
     "iopub.status.busy": "2025-07-02T15:28:09.033654Z",
     "iopub.status.idle": "2025-07-02T15:28:09.062930Z",
     "shell.execute_reply": "2025-07-02T15:28:09.062395Z",
     "shell.execute_reply.started": "2025-07-02T15:28:09.033815Z"
    },
    "id": "vHn0dlPHLUxJ",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(\"/kaggle/input/sp500-data/SP500 Vix (1).csv\")\n",
    "\n",
    "# Ensure the required columns exist\n",
    "if \"Price\" in df.columns and \"Open\" in df.columns:\n",
    "    # Calculate the percentage change\n",
    "    df[\"Change %\"] = ((df[\"Price\"] - df[\"Open\"]) / df[\"Price\"]) * 100\n",
    "\n",
    "    # Save the updated CSV file\n",
    "    # df.to_csv(\"SP 500 (2).csv\", index=False)\n",
    "\n",
    "    # Display first few rows\n",
    "    print(df.head())\n",
    "else:\n",
    "    print(\"Error: CSV file must contain 'Price' and 'Open' columns.\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T15:28:09.063952Z",
     "iopub.status.busy": "2025-07-02T15:28:09.063695Z",
     "iopub.status.idle": "2025-07-02T15:28:09.081796Z",
     "shell.execute_reply": "2025-07-02T15:28:09.081142Z",
     "shell.execute_reply.started": "2025-07-02T15:28:09.063926Z"
    },
    "id": "a0G89ghRLUxJ",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "vix = df\n",
    "vix.drop(\"Vol.\",axis=1,inplace=True)\n",
    "def convert_volume(val):\n",
    "    if pd.isna(val) or val == '-':  # Handle NaN or '-' cases\n",
    "        return np.nan\n",
    "    val = val.strip().replace(',', '')  # Remove spaces & commas\n",
    "    if val[-1] == 'K': return float(val[:-1]) * 1e3\n",
    "    if val[-1] == 'M': return float(val[:-1]) * 1e6\n",
    "    if val[-1] == 'B': return float(val[:-1]) * 1e9\n",
    "    return float(val)\n",
    "\n",
    "#vix[\"Vol.\"] = vix[\"Vol.\"].apply(convert_volume)\n",
    "vix.rename(columns={'Open':'Vopen','High':'Vhigh','Low':'Vlow','Change %':'Vchange%'}, inplace=True)\n",
    "vix[\"Vchange%\"] = vix[\"Vchange%\"].astype(str).str.replace(\"%\", \"\").astype(float)\n",
    "vix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T15:28:09.083070Z",
     "iopub.status.busy": "2025-07-02T15:28:09.082817Z",
     "iopub.status.idle": "2025-07-02T15:28:09.113881Z",
     "shell.execute_reply": "2025-07-02T15:28:09.113225Z",
     "shell.execute_reply.started": "2025-07-02T15:28:09.083047Z"
    },
    "id": "pi2PRu2xLUxK",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(\"/kaggle/input/sp500-data/sp500_historical_data (2).csv\")\n",
    "\n",
    "# Ensure the required columns exist\n",
    "if \"Price\" in df.columns and \"Open\" in df.columns:\n",
    "    # Calculate the percentage change\n",
    "    df[\"Change %\"] = ((df[\"Price\"] - df[\"Open\"]) / df[\"Price\"]) * 100\n",
    "\n",
    "    # Save the updated CSV file\n",
    "    # df.to_csv(\"SP 500 (2).csv\", index=False)\n",
    "\n",
    "    # Display first few rows\n",
    "    print(df.head())\n",
    "else:\n",
    "    print(\"Error: CSV file must contain 'Price' and 'Open' columns.\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T15:28:09.114878Z",
     "iopub.status.busy": "2025-07-02T15:28:09.114639Z",
     "iopub.status.idle": "2025-07-02T15:28:09.167567Z",
     "shell.execute_reply": "2025-07-02T15:28:09.167050Z",
     "shell.execute_reply.started": "2025-07-02T15:28:09.114857Z"
    },
    "id": "YC-kKgPJLUxK",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data=df\n",
    "data=data[::-1]\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "print(data.head())\n",
    "data.nunique()\n",
    "\n",
    "data.sort_index(axis=1,ascending=True)\n",
    "data.rename(columns={'Price': 'Close'}, inplace=True)\n",
    "df = data.copy()  # Ensure we don't modify the original dataset\n",
    "\n",
    "# Convert financial columns to numeric (remove commas)\n",
    "for col in [\"Close\", \"Open\", \"High\", \"Low\"]:\n",
    "    df[col] = df[col].astype(str).str.replace(\",\", \"\").astype(float)\n",
    "\n",
    "# Function to convert 'Vol.' column\n",
    "#df.drop(\"Vol.\",axis=1,inplace=True)\n",
    "\n",
    "# Convert 'Change %' column (remove '%' and convert to float)\n",
    "df[\"Change %\"] = df[\"Change %\"].astype(str).str.replace(\"%\", \"\").astype(float)\n",
    "\n",
    "# Print final DataFrame\n",
    "print(df.dtypes)\n",
    "print(df)\n",
    "\n",
    "# Assign back to 'data' (if needed)\n",
    "data = df\n",
    "#data['Date'] = pd.to_datetime(data['Date'], format=\"%d-%m-%Y\")\n",
    "\n",
    "# For 'vix', the date format is \"MM/DD/YYYY\"\n",
    "#vix['Date'] = pd.to_datetime(vix['Date'], format=\"%m/%d/%Y\")\n",
    "data = pd.merge(data, vix, on='Date', how='inner')\n",
    "#row=data[data[\"Vol.\"].isna()]\n",
    "data.drop(['Date'], axis=1, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T15:28:56.553035Z",
     "iopub.status.busy": "2025-07-02T15:28:56.552358Z",
     "iopub.status.idle": "2025-07-02T15:28:56.578637Z",
     "shell.execute_reply": "2025-07-02T15:28:56.577930Z",
     "shell.execute_reply.started": "2025-07-02T15:28:56.553013Z"
    },
    "id": "eOMIq62MLUxK",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, mean_absolute_percentage_error, explained_variance_score\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Input, Dense, Bidirectional, LSTM, Lambda, Concatenate, Add, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# 2. Load & Preprocess Data\n",
    "# ---------------------------\n",
    "# For demonstration, we use a basic univariate \"Close\" series.\n",
    "# Ensure that your DataFrame 'data' contains at least a \"Close\" column.\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# ---------------------------\n",
    "# 2. Load & Preprocess Data\n",
    "# ---------------------------\n",
    "# Separate features (X) and target (y)\n",
    "y = data[['Close']].copy()\n",
    "X = data.drop('Close', axis=1).copy()\n",
    "\n",
    "# It's important to scale your features and target separately.\n",
    "# We'll need the 'scaler_y' later to inverse the transformation of our predictions.\n",
    "scaler_X = MinMaxScaler()\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "\n",
    "scaler_y = MinMaxScaler()\n",
    "y_scaled = scaler_y.fit_transform(y)\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# 3. Create 15-day Sequences for Multivariate Data\n",
    "# ---------------------------\n",
    "def create_multivariate_sequences(X_data, y_data, time_steps=15):\n",
    "    \"\"\"\n",
    "    Creates sequences for multivariate time series data.\n",
    "    \"\"\"\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X_data) - time_steps):\n",
    "        # Get a sequence of 'time_steps' from the features\n",
    "        Xs.append(X_data[i:(i + time_steps)])\n",
    "        # The target is the 'Close' price at the end of the sequence\n",
    "        ys.append(y_data[i + time_steps])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "\n",
    "# Create the sequences\n",
    "X_seq, y_seq = create_multivariate_sequences(X_scaled, y_scaled, time_steps=15)\n",
    "\n",
    "# Split the data into training, validation, and testing sets\n",
    "train_size = int(len(X_seq) * 0.7)\n",
    "val_size = int(len(X_seq) * 0.1)\n",
    "\n",
    "X_train, y_train = X_seq[:train_size], y_seq[:train_size]\n",
    "X_val, y_val = X_seq[train_size:train_size + val_size], y_seq[train_size:train_size + val_size]\n",
    "X_test, y_test = X_seq[train_size + val_size:], y_seq[train_size + val_size:]\n",
    "\n",
    "# The input for the model will have a shape of (number of samples, timesteps, number of features)\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "n_features = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T15:28:56.579876Z",
     "iopub.status.busy": "2025-07-02T15:28:56.579685Z",
     "iopub.status.idle": "2025-07-02T15:30:26.605156Z",
     "shell.execute_reply": "2025-07-02T15:30:26.604476Z",
     "shell.execute_reply.started": "2025-07-02T15:28:56.579862Z"
    },
    "id": "8c2Z0t_XLUxL",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.layers import Multiply, Activation\n",
    "\n",
    "def build_lstm_model(seq_length=15,n_features=n_features, scale_factor=0.2, recent_scale=0.1):\n",
    "    inputs = Input(shape=(seq_length, n_features))\n",
    "    # Simple LSTM (unidirectional)\n",
    "    x = LSTM(128, return_sequences=False, dropout=0.2)(inputs)\n",
    "    x = Dense(16)(x)\n",
    "    x = Dense(1,activation=\"tanh\")(x)\n",
    "    x = Lambda(lambda x: x * scale_factor)(x)\n",
    "\n",
    "    # Use the last day's price for final output calculation\n",
    "    last_day = Lambda(lambda x: tf.expand_dims(x[:, -1, 0], axis=-1))(inputs)\n",
    "    final_output = Lambda(lambda inputs: inputs[0] * (1 + inputs[1]))([last_day, x])\n",
    "\n",
    "    model = Model(inputs, final_output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "    return model\n",
    "\n",
    "# *Build the Modified Model with Gating*\n",
    "# model_gated = build_gated_multi_scale_model(seq_length=15, scale_factor=0.2, recent_scale=0.1)\n",
    "# model_gated.summary()\n",
    "\n",
    "# *Build the Modified Model with Attention-Based Residuals*\n",
    "model_attention = build_lstm_model(seq_length=15, scale_factor=0.2, recent_scale=0.1)\n",
    "model_attention.summary()\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", patience=15, restore_best_weights=True, verbose=1)\n",
    "history = model_attention.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val), batch_size=8, callbacks=[early_stop], verbose=1)\n",
    "\n",
    "# ---------------------------\n",
    "# 7. Evaluate the Model\n",
    "# ---------------------------\n",
    "y_pred = model_attention.predict(X_test)\n",
    "# Predictions on test set\n",
    "##y_pred = model.predict(X_test)\n",
    "\n",
    "# Inverse transform predictions and actual values\n",
    "y_pred_inv = scaler_y.inverse_transform(y_pred)\n",
    "y_test_inv = scaler_y.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Inverse transform predictions and actual values\n",
    "y_pred_inv = scaler_y.inverse_transform(y_pred)\n",
    "y_test_inv = scaler_y.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Calculate Metrics\n",
    "r2 = r2_score(y_test_inv, y_pred_inv)\n",
    "mae = mean_absolute_error(y_test_inv, y_pred_inv)\n",
    "mse = mean_squared_error(y_test_inv, y_pred_inv)\n",
    "rmse = np.sqrt(mse)  # Root Mean Squared Error\n",
    "\n",
    "# Calculate the actual range of the test set\n",
    "actual_range = np.max(y_test_inv) - np.min(y_test_inv)\n",
    "\n",
    "# Compute Scaled Metrics\n",
    "mae_scaled = mae / actual_range\n",
    "mse_scaled = mse / (actual_range ** 2)\n",
    "rmse_scaled = rmse / actual_range\n",
    "\n",
    "# Explained Variance Score\n",
    "evs = explained_variance_score(y_test_inv, y_pred_inv)\n",
    "\n",
    "# Print the results\n",
    "print(f\"ðŸ“Š Final Results -\")\n",
    "print(f\"  RÂ²: {r2:.4f}\")\n",
    "print(f\"  MAE: {mae:.4f}, MAE Scaled: {mae_scaled:.4f}\")\n",
    "print(f\"  MSE: {mse:.4f}, MSE Scaled: {mse_scaled:.4f}\")\n",
    "print(f\"  RMSE: {rmse:.4f}, RMSE Scaled: {rmse_scaled:.4f}\")\n",
    "print(f\"  MAPE: {mean_absolute_percentage_error(y_test_inv, y_pred_inv) * 100:.2f}%\")\n",
    "print(f\"  EVS: {evs:.4f}\")\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot the first 100 points for better visibility\n",
    "num_points = min(100, len(y_test_inv))\n",
    "\n",
    "plt.plot(y_test_inv[:num_points], label=\"Actual\", linestyle=\"-\", linewidth=2, marker=\"o\", markersize=3, alpha=0.8)\n",
    "plt.plot(y_pred_inv[:num_points], label=\"Predicted\", linestyle=\"--\", linewidth=2, marker=\"x\", markersize=3, alpha=0.8)\n",
    "\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Stock Price\")\n",
    "plt.title(\"Actual vs Predicted Stock Prices (Zoomed In)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T15:30:26.606634Z",
     "iopub.status.busy": "2025-07-02T15:30:26.606428Z",
     "iopub.status.idle": "2025-07-02T15:32:21.373885Z",
     "shell.execute_reply": "2025-07-02T15:32:21.373221Z",
     "shell.execute_reply.started": "2025-07-02T15:30:26.606618Z"
    },
    "id": "8BSLUFZZLUxL",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Multiply, Activation\n",
    "\n",
    "def build_Bilstm1_model(seq_length=15,n_features=n_features, scale_factor=0.2, recent_scale=0.1):\n",
    "    inputs = Input(shape=(seq_length, n_features))\n",
    "    # 15-day full branch with BiLSTM\n",
    "    x = Bidirectional(LSTM(128, return_sequences=False, dropout=0.2))(inputs)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dense(1, activation='tanh')(x)\n",
    "    x = Lambda(lambda x: x * scale_factor)(x)\n",
    "\n",
    "    last_day = Lambda(lambda x: tf.expand_dims(x[:, -1, 0], axis=-1))(inputs)\n",
    "    final_output = Lambda(lambda inputs: inputs[0] * (1 + inputs[1]))([last_day, x])\n",
    "\n",
    "    model = Model(inputs, final_output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "    return model\n",
    "\n",
    "# *Build the Modified Model with Gating*\n",
    "# model_gated = build_gated_multi_scale_model(seq_length=15, scale_factor=0.2, recent_scale=0.1)\n",
    "# model_gated.summary()\n",
    "\n",
    "# *Build the Modified Model with Attention-Based Residuals*\n",
    "model_attention = build_Bilstm1_model(seq_length=15, scale_factor=0.2, recent_scale=0.1)\n",
    "model_attention.summary()\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", patience=15, restore_best_weights=True, verbose=1)\n",
    "history = model_attention.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val), batch_size=8, callbacks=[early_stop], verbose=1)\n",
    "\n",
    "# ---------------------------\n",
    "# 7. Evaluate the Model\n",
    "# ---------------------------\n",
    "y_pred = model_attention.predict(X_test)\n",
    "# Predictions on test set\n",
    "##y_pred = model.predict(X_test)\n",
    "\n",
    "# Inverse transform predictions and actual values\n",
    "y_pred_inv = scaler_y.inverse_transform(y_pred)\n",
    "y_test_inv = scaler_y.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Inverse transform predictions and actual values\n",
    "y_pred_inv = scaler_y.inverse_transform(y_pred)\n",
    "y_test_inv = scaler_y.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Calculate Metrics\n",
    "r2 = r2_score(y_test_inv, y_pred_inv)\n",
    "mae = mean_absolute_error(y_test_inv, y_pred_inv)\n",
    "mse = mean_squared_error(y_test_inv, y_pred_inv)\n",
    "rmse = np.sqrt(mse)  # Root Mean Squared Error\n",
    "\n",
    "# Calculate the actual range of the test set\n",
    "actual_range = np.max(y_test_inv) - np.min(y_test_inv)\n",
    "\n",
    "# Compute Scaled Metrics\n",
    "mae_scaled = mae / actual_range\n",
    "mse_scaled = mse / (actual_range ** 2)\n",
    "rmse_scaled = rmse / actual_range\n",
    "\n",
    "# Explained Variance Score\n",
    "evs = explained_variance_score(y_test_inv, y_pred_inv)\n",
    "\n",
    "# Print the results\n",
    "print(f\"ðŸ“Š Final Results -\")\n",
    "print(f\"  RÂ²: {r2:.4f}\")\n",
    "print(f\"  MAE: {mae:.4f}, MAE Scaled: {mae_scaled:.4f}\")\n",
    "print(f\"  MSE: {mse:.4f}, MSE Scaled: {mse_scaled:.4f}\")\n",
    "print(f\"  RMSE: {rmse:.4f}, RMSE Scaled: {rmse_scaled:.4f}\")\n",
    "print(f\"  MAPE: {mean_absolute_percentage_error(y_test_inv, y_pred_inv) * 100:.2f}%\")\n",
    "print(f\"  EVS: {evs:.4f}\")\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot the first 100 points for better visibility\n",
    "num_points = min(100, len(y_test_inv))\n",
    "\n",
    "plt.plot(y_test_inv[:num_points], label=\"Actual\", linestyle=\"-\", linewidth=2, marker=\"o\", markersize=3, alpha=0.8)\n",
    "plt.plot(y_pred_inv[:num_points], label=\"Predicted\", linestyle=\"--\", linewidth=2, marker=\"x\", markersize=3, alpha=0.8)\n",
    "\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Stock Price\")\n",
    "plt.title(\"Actual vs Predicted Stock Prices (Zoomed In)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T15:32:21.375002Z",
     "iopub.status.busy": "2025-07-02T15:32:21.374732Z",
     "iopub.status.idle": "2025-07-02T15:35:12.168604Z",
     "shell.execute_reply": "2025-07-02T15:35:12.167858Z",
     "shell.execute_reply.started": "2025-07-02T15:32:21.374975Z"
    },
    "id": "vTqh36-VLUxL",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.layers import Multiply, Activation\n",
    "\n",
    "def build_Bilstm2_model(seq_length=15,n_features=n_features, scale_factor=0.2, recent_scale=0.1):\n",
    "    inputs = Input(shape=(seq_length, n_features))\n",
    "\n",
    "    # Full branch (15 days)\n",
    "    full_branch = Bidirectional(LSTM(128, return_sequences=False, dropout=0.2))(inputs)\n",
    "    full_branch = Dense(64, activation='relu')(full_branch)\n",
    "    long_term_return = Dense(1, activation='tanh')(full_branch)\n",
    "    long_term_return = Lambda(lambda x: x * scale_factor)(long_term_return)\n",
    "\n",
    "    # Recent branch (last 7 days)\n",
    "    recent_input = Lambda(lambda x: x[:, -7:, :])(inputs)\n",
    "    recent_branch = Bidirectional(LSTM(128, return_sequences=False, dropout=0.2))(recent_input)\n",
    "    recent_branch = Dense(64, activation='relu')(recent_branch)\n",
    "    mid_term_return = Dense(1, activation='tanh')(recent_branch)\n",
    "    mid_term_return = Lambda(lambda x: x * scale_factor)(mid_term_return)\n",
    "\n",
    "    # Gate the 7-day branch output\n",
    "    gate_7 = Dense(1, activation='sigmoid')(mid_term_return)\n",
    "    gated_mid_term_return = Multiply()([mid_term_return, gate_7])\n",
    "\n",
    "    # Fuse the two branches\n",
    "    fused_returns = Add()([long_term_return, gated_mid_term_return])\n",
    "    fused_returns = Dense(32, activation='relu')(fused_returns)\n",
    "    final_return = Dense(1, activation='tanh')(fused_returns)\n",
    "    final_return = Lambda(lambda x: x * scale_factor)(final_return)\n",
    "\n",
    "    last_day = Lambda(lambda x: tf.expand_dims(x[:, -1, 0], axis=-1))(inputs)\n",
    "    final_output = Lambda(lambda inputs: inputs[0] * (1 + inputs[1]))([last_day, final_return])\n",
    "\n",
    "    model = Model(inputs, final_output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "    return model\n",
    "\n",
    "# *Build the Modified Model with Gating*\n",
    "# model_gated = build_gated_multi_scale_model(seq_length=15, scale_factor=0.2, recent_scale=0.1)\n",
    "# model_gated.summary()\n",
    "\n",
    "# *Build the Modified Model with Attention-Based Residuals*\n",
    "model_attention = build_Bilstm2_model(seq_length=15, scale_factor=0.2, recent_scale=0.1)\n",
    "model_attention.summary()\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", patience=15, restore_best_weights=True, verbose=1)\n",
    "history = model_attention.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val), batch_size=8, callbacks=[early_stop], verbose=1)\n",
    "\n",
    "# ---------------------------\n",
    "# 7. Evaluate the Model\n",
    "# ---------------------------\n",
    "y_pred = model_attention.predict(X_test)\n",
    "# Predictions on test set\n",
    "##y_pred = model.predict(X_test)\n",
    "\n",
    "# Inverse transform predictions and actual values\n",
    "y_pred_inv = scaler_y.inverse_transform(y_pred)\n",
    "y_test_inv = scaler_y.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Inverse transform predictions and actual values\n",
    "y_pred_inv = scaler_y.inverse_transform(y_pred)\n",
    "y_test_inv = scaler_y.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Calculate Metrics\n",
    "r2 = r2_score(y_test_inv, y_pred_inv)\n",
    "mae = mean_absolute_error(y_test_inv, y_pred_inv)\n",
    "mse = mean_squared_error(y_test_inv, y_pred_inv)\n",
    "rmse = np.sqrt(mse)  # Root Mean Squared Error\n",
    "\n",
    "# Calculate the actual range of the test set\n",
    "actual_range = np.max(y_test_inv) - np.min(y_test_inv)\n",
    "\n",
    "# Compute Scaled Metrics\n",
    "mae_scaled = mae / actual_range\n",
    "mse_scaled = mse / (actual_range ** 2)\n",
    "rmse_scaled = rmse / actual_range\n",
    "\n",
    "# Explained Variance Score\n",
    "evs = explained_variance_score(y_test_inv, y_pred_inv)\n",
    "\n",
    "# Print the results\n",
    "print(f\"ðŸ“Š Final Results -\")\n",
    "print(f\"  RÂ²: {r2:.4f}\")\n",
    "print(f\"  MAE: {mae:.4f}, MAE Scaled: {mae_scaled:.4f}\")\n",
    "print(f\"  MSE: {mse:.4f}, MSE Scaled: {mse_scaled:.4f}\")\n",
    "print(f\"  RMSE: {rmse:.4f}, RMSE Scaled: {rmse_scaled:.4f}\")\n",
    "print(f\"  MAPE: {mean_absolute_percentage_error(y_test_inv, y_pred_inv) * 100:.2f}%\")\n",
    "print(f\"  EVS: {evs:.4f}\")\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot the first 100 points for better visibility\n",
    "num_points = min(100, len(y_test_inv))\n",
    "\n",
    "plt.plot(y_test_inv[:num_points], label=\"Actual\", linestyle=\"-\", linewidth=2, marker=\"o\", markersize=3, alpha=0.8)\n",
    "plt.plot(y_pred_inv[:num_points], label=\"Predicted\", linestyle=\"--\", linewidth=2, marker=\"x\", markersize=3, alpha=0.8)\n",
    "\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Stock Price\")\n",
    "plt.title(\"Actual vs Predicted Stock Prices (Zoomed In)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T15:35:12.170419Z",
     "iopub.status.busy": "2025-07-02T15:35:12.170201Z",
     "iopub.status.idle": "2025-07-02T15:40:01.699925Z",
     "shell.execute_reply": "2025-07-02T15:40:01.699160Z",
     "shell.execute_reply.started": "2025-07-02T15:35:12.170403Z"
    },
    "id": "bOBU14BxLUxM",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.layers import Multiply, Activation\n",
    "\n",
    "def build_Bilstm3_model(seq_length=15,n_features=n_features, scale_factor=0.2, recent_scale=0.1):\n",
    "    inputs = Input(shape=(seq_length, n_features))\n",
    "\n",
    "    # Recent branch (last 7 days)\n",
    "    recent_input = Lambda(lambda x: x[:, -7:, :])(inputs)\n",
    "    recent_branch = Bidirectional(LSTM(128, return_sequences=False, dropout=0.2))(recent_input)\n",
    "    recent_branch = Dense(64, activation='relu')(recent_branch)\n",
    "    mid_term_return = Dense(1, activation='tanh')(recent_branch)\n",
    "    mid_term_return = Lambda(lambda x: x * scale_factor)(mid_term_return)\n",
    "\n",
    "    # Very recent branch (last 1 day)\n",
    "    very_recent_input = Lambda(lambda x: x[:, -1:, :])(inputs)\n",
    "    very_recent_branch = Flatten()(very_recent_input)\n",
    "    very_recent_branch = Dense(32, activation='relu')(very_recent_branch)\n",
    "    short_term_return = Dense(1, activation='tanh')(very_recent_branch)\n",
    "    short_term_return = Lambda(lambda x: x * recent_scale)(short_term_return)\n",
    "\n",
    "    # Gating mechanisms\n",
    "    gate_7 = Dense(1, activation='sigmoid')(mid_term_return)\n",
    "    gate_1 = Dense(1, activation='sigmoid')(short_term_return)\n",
    "    gated_mid_term_return = Multiply()([mid_term_return, gate_7])\n",
    "    gated_short_term_return = Multiply()([short_term_return, gate_1])\n",
    "\n",
    "    # Combine gated outputs\n",
    "    fused_returns = Add()([gated_mid_term_return, gated_short_term_return])\n",
    "    fused_returns = Dense(32, activation='relu')(fused_returns)\n",
    "    final_return = Dense(1, activation='tanh')(fused_returns)\n",
    "    final_return = Lambda(lambda x: x * scale_factor)(final_return)\n",
    "\n",
    "    last_day = Lambda(lambda x: tf.expand_dims(x[:, -1, 0], axis=-1))(inputs)\n",
    "    final_output = Lambda(lambda inputs: inputs[0] * (1 + inputs[1]))([last_day, final_return])\n",
    "\n",
    "    model = Model(inputs, final_output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "    return model\n",
    "\n",
    "# *Build the Modified Model with Gating*\n",
    "# model_gated = build_gated_multi_scale_model(seq_length=15, scale_factor=0.2, recent_scale=0.1)\n",
    "# model_gated.summary()\n",
    "\n",
    "# *Build the Modified Model with Attention-Based Residuals*\n",
    "model_attention = build_Bilstm3_model(seq_length=15, scale_factor=0.2, recent_scale=0.1)\n",
    "model_attention.summary()\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", patience=15, restore_best_weights=True, verbose=1)\n",
    "history = model_attention.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val), batch_size=8, callbacks=[early_stop], verbose=1)\n",
    "\n",
    "# ---------------------------\n",
    "# 7. Evaluate the Model\n",
    "# ---------------------------\n",
    "y_pred = model_attention.predict(X_test)\n",
    "# Predictions on test set\n",
    "##y_pred = model.predict(X_test)\n",
    "\n",
    "# Inverse transform predictions and actual values\n",
    "y_pred_inv = scaler_y.inverse_transform(y_pred)\n",
    "y_test_inv = scaler_y.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Inverse transform predictions and actual values\n",
    "y_pred_inv = scaler_y.inverse_transform(y_pred)\n",
    "y_test_inv = scaler_y.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Calculate Metrics\n",
    "r2 = r2_score(y_test_inv, y_pred_inv)\n",
    "mae = mean_absolute_error(y_test_inv, y_pred_inv)\n",
    "mse = mean_squared_error(y_test_inv, y_pred_inv)\n",
    "rmse = np.sqrt(mse)  # Root Mean Squared Error\n",
    "\n",
    "# Calculate the actual range of the test set\n",
    "actual_range = np.max(y_test_inv) - np.min(y_test_inv)\n",
    "\n",
    "# Compute Scaled Metrics\n",
    "mae_scaled = mae / actual_range\n",
    "mse_scaled = mse / (actual_range ** 2)\n",
    "rmse_scaled = rmse / actual_range\n",
    "\n",
    "# Explained Variance Score\n",
    "evs = explained_variance_score(y_test_inv, y_pred_inv)\n",
    "\n",
    "# Print the results\n",
    "print(f\"ðŸ“Š Final Results -\")\n",
    "print(f\"  RÂ²: {r2:.4f}\")\n",
    "print(f\"  MAE: {mae:.4f}, MAE Scaled: {mae_scaled:.4f}\")\n",
    "print(f\"  MSE: {mse:.4f}, MSE Scaled: {mse_scaled:.4f}\")\n",
    "print(f\"  RMSE: {rmse:.4f}, RMSE Scaled: {rmse_scaled:.4f}\")\n",
    "print(f\"  MAPE: {mean_absolute_percentage_error(y_test_inv, y_pred_inv) * 100:.2f}%\")\n",
    "print(f\"  EVS: {evs:.4f}\")\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot the first 100 points for better visibility\n",
    "num_points = min(100, len(y_test_inv))\n",
    "\n",
    "plt.plot(y_test_inv[:num_points], label=\"Actual\", linestyle=\"-\", linewidth=2, marker=\"o\", markersize=3, alpha=0.8)\n",
    "plt.plot(y_pred_inv[:num_points], label=\"Predicted\", linestyle=\"--\", linewidth=2, marker=\"x\", markersize=3, alpha=0.8)\n",
    "\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Stock Price\")\n",
    "plt.title(\"Actual vs Predicted Stock Prices (Zoomed In)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T15:40:01.701012Z",
     "iopub.status.busy": "2025-07-02T15:40:01.700753Z",
     "iopub.status.idle": "2025-07-02T15:47:06.940304Z",
     "shell.execute_reply": "2025-07-02T15:47:06.939649Z",
     "shell.execute_reply.started": "2025-07-02T15:40:01.700994Z"
    },
    "id": "MolyL54mLUxM",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.layers import Multiply, Activation\n",
    "\n",
    "def build_Bilstm5_model(seq_length=15,n_features=n_features, scale_factor=0.2, recent_scale=0.1):\n",
    "    inputs = Input(shape=(seq_length, n_features))\n",
    "\n",
    "    # Full branch (15 days)\n",
    "    full_branch = Bidirectional(LSTM(128, return_sequences=False, dropout=0.2))(inputs)\n",
    "    full_branch = Dense(64, activation='relu')(full_branch)\n",
    "    long_term_return = Dense(1, activation='tanh')(full_branch)\n",
    "    long_term_return = Lambda(lambda x: x * scale_factor)(long_term_return)\n",
    "\n",
    "    # Recent branch (7 days)\n",
    "    recent_input = Lambda(lambda x: x[:, -7:, :])(inputs)\n",
    "    recent_branch = Bidirectional(LSTM(128, return_sequences=False, dropout=0.2))(recent_input)\n",
    "    recent_branch = Dense(64, activation='relu')(recent_branch)\n",
    "    mid_term_return = Dense(1, activation='tanh')(recent_branch)\n",
    "    mid_term_return = Lambda(lambda x: x * scale_factor)(mid_term_return)\n",
    "\n",
    "    # Very recent branch (1 day)\n",
    "    very_recent_input = Lambda(lambda x: x[:, -1:, :])(inputs)\n",
    "    very_recent_branch = Flatten()(very_recent_input)\n",
    "    very_recent_branch = Dense(32, activation='relu')(very_recent_branch)\n",
    "    short_term_return = Dense(1, activation='tanh')(very_recent_branch)\n",
    "    short_term_return = Lambda(lambda x: x * recent_scale)(short_term_return)\n",
    "\n",
    "    # Gating mechanisms\n",
    "    gate_7 = Dense(1, activation='sigmoid')(mid_term_return)\n",
    "    gate_1 = Dense(1, activation='sigmoid')(short_term_return)\n",
    "    gated_mid_term_return = Multiply()([mid_term_return, gate_7])\n",
    "    gated_short_term_return = Multiply()([short_term_return, gate_1])\n",
    "\n",
    "    # Fuse all branches\n",
    "    fused_returns = Add()([long_term_return, gated_mid_term_return, gated_short_term_return])\n",
    "    fused_returns = Dense(32, activation='relu')(fused_returns)\n",
    "    final_return = Dense(1, activation='tanh')(fused_returns)\n",
    "    final_return = Lambda(lambda x: x * scale_factor)(final_return)\n",
    "\n",
    "    last_day = Lambda(lambda x: tf.expand_dims(x[:, -1, 0], axis=-1))(inputs)\n",
    "    final_output = Lambda(lambda inputs: inputs[0] * (1 + inputs[1]))([last_day, final_return])\n",
    "\n",
    "    model = Model(inputs, final_output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "    return model\n",
    "\n",
    "# *Build the Modified Model with Gating*\n",
    "# model_gated = build_gated_multi_scale_model(seq_length=15, scale_factor=0.2, recent_scale=0.1)\n",
    "# model_gated.summary()\n",
    "\n",
    "# *Build the Modified Model with Attention-Based Residuals*\n",
    "model_attention = build_Bilstm5_model(seq_length=15, scale_factor=0.2, recent_scale=0.1)\n",
    "model_attention.summary()\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", patience=15, restore_best_weights=True, verbose=1)\n",
    "history = model_attention.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val), batch_size=8, callbacks=[early_stop], verbose=1)\n",
    "\n",
    "# ---------------------------\n",
    "# 7. Evaluate the Model\n",
    "# ---------------------------\n",
    "y_pred = model_attention.predict(X_test)\n",
    "# Predictions on test set\n",
    "##y_pred = model.predict(X_test)\n",
    "\n",
    "# Inverse transform predictions and actual values\n",
    "y_pred_inv = scaler_y.inverse_transform(y_pred)\n",
    "y_test_inv = scaler_y.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Inverse transform predictions and actual values\n",
    "y_pred_inv = scaler_y.inverse_transform(y_pred)\n",
    "y_test_inv = scaler_y.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Calculate Metrics\n",
    "r2 = r2_score(y_test_inv, y_pred_inv)\n",
    "mae = mean_absolute_error(y_test_inv, y_pred_inv)\n",
    "mse = mean_squared_error(y_test_inv, y_pred_inv)\n",
    "rmse = np.sqrt(mse)  # Root Mean Squared Error\n",
    "\n",
    "# Calculate the actual range of the test set\n",
    "actual_range = np.max(y_test_inv) - np.min(y_test_inv)\n",
    "\n",
    "# Compute Scaled Metrics\n",
    "mae_scaled = mae / actual_range\n",
    "mse_scaled = mse / (actual_range ** 2)\n",
    "rmse_scaled = rmse / actual_range\n",
    "\n",
    "# Explained Variance Score\n",
    "evs = explained_variance_score(y_test_inv, y_pred_inv)\n",
    "\n",
    "# Print the results\n",
    "print(f\"ðŸ“Š Final Results -\")\n",
    "print(f\"  RÂ²: {r2:.4f}\")\n",
    "print(f\"  MAE: {mae:.4f}, MAE Scaled: {mae_scaled:.4f}\")\n",
    "print(f\"  MSE: {mse:.4f}, MSE Scaled: {mse_scaled:.4f}\")\n",
    "print(f\"  RMSE: {rmse:.4f}, RMSE Scaled: {rmse_scaled:.4f}\")\n",
    "print(f\"  MAPE: {mean_absolute_percentage_error(y_test_inv, y_pred_inv) * 100:.2f}%\")\n",
    "print(f\"  EVS: {evs:.4f}\")\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot the first 100 points for better visibility\n",
    "num_points = max(100, len(y_test_inv))\n",
    "\n",
    "plt.plot(y_test_inv[:num_points], label=\"Actual\", linestyle=\"-\", linewidth=2, marker=\"o\", markersize=3, alpha=0.8)\n",
    "plt.plot(y_pred_inv[:num_points], label=\"Predicted\", linestyle=\"--\", linewidth=2, marker=\"x\", markersize=3, alpha=0.8)\n",
    "\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Stock Price\")\n",
    "plt.title(\"Actual vs Predicted Stock Prices (Zoomed In)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "num_points = max(100, len(y_test_inv))\n",
    "\n",
    "# Actual: Royal Blue\n",
    "plt.plot(\n",
    "    y_test_inv[:num_points],\n",
    "    label=\"Actual\",\n",
    "    linestyle=\"-\",\n",
    "    linewidth=3.5,\n",
    "    color=\"#4169E1\"  # Royal Blue\n",
    ")\n",
    "\n",
    "# Predicted: Crimson Red\n",
    "plt.plot(\n",
    "    y_pred_inv[:num_points],\n",
    "    label=\"Predicted\",\n",
    "    linestyle=\"--\",\n",
    "    linewidth=3.5,\n",
    "    color=\"#DC143C\"  # Crimson Red\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Time\", fontsize=14, fontweight=\"bold\")\n",
    "plt.ylabel(\"Stock Price\", fontsize=14, fontweight=\"bold\")\n",
    "plt.title(\"Actual vs Predicted Stock Prices\", fontsize=16, fontweight=\"bold\")\n",
    "\n",
    "plt.legend(fontsize=12, loc=\"upper left\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T15:47:06.941328Z",
     "iopub.status.busy": "2025-07-02T15:47:06.941112Z",
     "iopub.status.idle": "2025-07-02T15:47:07.366944Z",
     "shell.execute_reply": "2025-07-02T15:47:07.366223Z",
     "shell.execute_reply.started": "2025-07-02T15:47:06.941313Z"
    },
    "id": "6fMOqxIELUxN",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "num_points = max(100, len(y_test_inv))\n",
    "\n",
    "plt.plot(y_test_inv[:num_points], label=\"Actual\", linestyle=\"-\", linewidth=2, marker=\"o\", markersize=3, alpha=0.8)\n",
    "plt.plot(y_pred_inv[:num_points], label=\"Predicted\", linestyle=\"--\", linewidth=2, marker=\"x\", markersize=3, alpha=0.8)\n",
    "\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Stock Price\")\n",
    "plt.title(\"Actual vs Predicted Stock Prices\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "num_points = max(100, len(y_test_inv))\n",
    "\n",
    "# Actual: Royal Blue\n",
    "plt.plot(\n",
    "    y_test_inv[:num_points],\n",
    "    label=\"Actual\",\n",
    "    linestyle=\"-\",\n",
    "    linewidth=3.5,\n",
    "    color=\"#4169E1\"  # Royal Blue\n",
    ")\n",
    "\n",
    "# Predicted: Crimson Red\n",
    "plt.plot(\n",
    "    y_pred_inv[:num_points],\n",
    "    label=\"Predicted\",\n",
    "    linestyle=\"--\",\n",
    "    linewidth=3.5,\n",
    "    color=\"#DC143C\"  # Crimson Red\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Time\", fontsize=14, fontweight=\"bold\")\n",
    "plt.ylabel(\"Stock Price\", fontsize=14, fontweight=\"bold\")\n",
    "plt.title(\"Actual vs Predicted Stock Prices\", fontsize=16, fontweight=\"bold\")\n",
    "\n",
    "plt.legend(fontsize=12, loc=\"upper left\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T15:47:07.367918Z",
     "iopub.status.busy": "2025-07-02T15:47:07.367674Z",
     "iopub.status.idle": "2025-07-02T15:47:07.550122Z",
     "shell.execute_reply": "2025-07-02T15:47:07.549486Z",
     "shell.execute_reply.started": "2025-07-02T15:47:07.367877Z"
    },
    "id": "ZVVSJ4jALUxN",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "num_points = min(100, len(y_test_inv))\n",
    "\n",
    "plt.plot(y_test_inv[:num_points], label=\"Actual\", linestyle=\"-\", linewidth=2, marker=\"o\", markersize=3, alpha=0.8)\n",
    "plt.plot(y_pred_inv[:num_points], label=\"Predicted\", linestyle=\"--\", linewidth=2, marker=\"x\", markersize=3, alpha=0.8)\n",
    "\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Stock Price\")\n",
    "plt.title(\"Actual vs Predicted Stock Prices\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-C67nhK_LUxN",
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6790221,
     "sourceId": 10921810,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6861289,
     "sourceId": 11019285,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
